---
title: Azure Kubernetes Service (AKS) 上のマイクロサービス アーキテクチャ
description: Azure Kubernetes Service (AKS) 上にマイクロサービス アーキテクチャをデプロイする
author: MikeWasson
ms.date: 12/10/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: microservices
ms.openlocfilehash: c8ce4c77666ab7b9c55e6f144d514fadc6b6ad73
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/20/2019
ms.locfileid: "58246083"
---
# <a name="microservices-architecture-on-azure-kubernetes-service-aks"></a><span data-ttu-id="85ca1-103">Azure Kubernetes Service (AKS) 上のマイクロサービス アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="85ca1-103">Microservices architecture on Azure Kubernetes Service (AKS)</span></span>

<span data-ttu-id="85ca1-104">この参照アーキテクチャは、Azure Kubernetes Service (AKS) にデプロイされたマイクロサービス アプリケーションを示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-104">This reference architectures shows a microservices application deployed to Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="85ca1-105">ここには、ほとんどのデプロイの出発点にすることができる基本的な AKS 構成が示されています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-105">It shows a basic AKS configuration that can be the starting point for most deployments.</span></span> <span data-ttu-id="85ca1-106">より詳細なオプション (詳細なネットワーク オプションを含む) は、別の参照アーキテクチャで説明されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-106">More advanced options, including advanced networking options, will be covered in a separate reference architecture.</span></span>

<span data-ttu-id="85ca1-107">この記事では、Kubernetes の基本的な知識を前提にしています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-107">This article assumes basic knowledge of Kubernetes.</span></span> <span data-ttu-id="85ca1-108">この記事は主に、AKS 上でマイクロサービス アーキテクチャを実行するためのインフラストラクチャと DevOps に関する考慮事項に重点を置いています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-108">The article focuses mainly on the infrastructure and DevOps considerations of running a microservices architecture on AKS.</span></span> <span data-ttu-id="85ca1-109">ドメインベースの設計 (DDD) の観点からマイクロサービスを設計する方法に関するガイダンスについては、「[Azure でのマイクロサービスの設計、構築、および操作](/azure/architecture/microservices)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-109">For guidance on how to design microservices from a Domain Driven Design (DDD) perspective, see [Designing, building, and operating microservices on Azure](/azure/architecture/microservices).</span></span>

![AKS の参照アーキテクチャ](./_images/aks.png)

## <a name="architecture"></a><span data-ttu-id="85ca1-111">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="85ca1-111">Architecture</span></span>

<span data-ttu-id="85ca1-112">アーキテクチャは、次のコンポーネントで構成されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-112">The architecture consists of the following components.</span></span>

<span data-ttu-id="85ca1-113">**Azure Kubernetes Service** (AKS)。</span><span class="sxs-lookup"><span data-stu-id="85ca1-113">**Azure Kubernetes Service** (AKS).</span></span> <span data-ttu-id="85ca1-114">AKS は、マネージド Kubernetes クラスターをデプロイする Azure サービスです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-114">AKS is an Azure service that deploys a managed Kubernetes cluster.</span></span> 

<span data-ttu-id="85ca1-115">**Kubernetes クラスター**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-115">**Kubernetes cluster**.</span></span> <span data-ttu-id="85ca1-116">AKS は Kubernetes クラスターをデプロイしたり、Kubernetes マスターを管理したりする役割を果たします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-116">AKS is responsible for deploying the Kubernetes cluster and for managing the Kubernetes masters.</span></span> <span data-ttu-id="85ca1-117">ユーザーは、エージェント ノードを管理するだけです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-117">You only manage the agent nodes.</span></span>

<span data-ttu-id="85ca1-118">**Virtual network**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-118">**Virtual network**.</span></span> <span data-ttu-id="85ca1-119">既定では、AKS はエージェント ノードをデプロイするための仮想ネットワークを作成します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-119">By default, AKS creates a virtual network to deploy the agent nodes into.</span></span> <span data-ttu-id="85ca1-120">より高度なシナリオでは、ユーザーが最初に仮想ネットワークを作成できます。それにより、サブネットの構成方法、オンプレミスの接続、IP アドレスの指定などを制御できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-120">For more advanced scenarios, you can create the virtual network first, which lets you control things like how the subnets are configured, on-premises connectivity, and IP addressing.</span></span> <span data-ttu-id="85ca1-121">詳細については、[Azure Kubernetes Service (AKS) での高度なネットワークの構成](/azure/aks/configure-advanced-networking)に関するページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-121">For more information, see [Configure advanced networking in Azure Kubernetes Service (AKS)](/azure/aks/configure-advanced-networking).</span></span>

<span data-ttu-id="85ca1-122">**イングレス**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-122">**Ingress**.</span></span> <span data-ttu-id="85ca1-123">イングレスは、クラスター内のサービスに HTTP(S) ルートを公開します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-123">An ingress exposes HTTP(S) routes to services inside the cluster.</span></span> <span data-ttu-id="85ca1-124">詳細については、後の「[API ゲートウェイ](#api-gateway)」のセクションを参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-124">For more information, see the section [API Gateway](#api-gateway) below.</span></span>

<span data-ttu-id="85ca1-125">**外部データ ストア**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-125">**External data stores**.</span></span> <span data-ttu-id="85ca1-126">マイクロサービスは通常ステートレスであり、Azure SQL Database や Cosmos DB などの外部データ ストアに状態を書き込みます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-126">Microservices are typically stateless and write state to external data stores, such as Azure SQL Database or Cosmos DB.</span></span>

<span data-ttu-id="85ca1-127">**Azure Active Directory**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-127">**Azure Active Directory**.</span></span> <span data-ttu-id="85ca1-128">AKS は、Azure ロード バランサーなどの他の Azure リソースを作成および管理するために Azure Active Directory (Azure AD) ID を使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-128">AKS uses an Azure Active Directory (Azure AD) identity to create and manage other Azure resources such as Azure load balancers.</span></span> <span data-ttu-id="85ca1-129">Azure AD はまた、クライアント アプリケーションでのユーザー認証にも推奨されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-129">Azure AD is also recommended for user authentication in client applications.</span></span>

<span data-ttu-id="85ca1-130">**Azure Container Registry**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-130">**Azure Container Registry**.</span></span> <span data-ttu-id="85ca1-131">Container Registry は、クラスターにデプロイされたプライベート Docker イメージを格納するために使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-131">Use Container Registry to store private Docker images, which are deployed to the cluster.</span></span> <span data-ttu-id="85ca1-132">AKS は、その Azure AD ID を使用して Container Registry に対して認証できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-132">AKS can authenticate with Container Registry using its Azure AD identity.</span></span> <span data-ttu-id="85ca1-133">AKS に Azure Container Registry は必要ないことに注意してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-133">Note that AKS does not require Azure Container Registry.</span></span> <span data-ttu-id="85ca1-134">Docker Hub などの他のコンテナー レジストリを使用できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-134">You can use other container registries, such as Docker Hub.</span></span>

<span data-ttu-id="85ca1-135">**Azure Pipelines**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-135">**Azure Pipelines**.</span></span> <span data-ttu-id="85ca1-136">Pipelines は Azure DevOps Services の一部であり、自動化された構築、テスト、およびデプロイを実行します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-136">Pipelines is part of Azure DevOps Services and runs automated builds, tests, and deployments.</span></span> <span data-ttu-id="85ca1-137">Jenkins などのサードパーティ CI/CD ソリューションも使用できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-137">You can also use third-party CI/CD solutions such as Jenkins.</span></span> 

<span data-ttu-id="85ca1-138">**Helm**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-138">**Helm**.</span></span> <span data-ttu-id="85ca1-139">Helm は Kubernetes のパッケージ マネージャーであり、Kubernetes オブジェクトを発行、デプロイ、バージョン管理、および更新が可能な 1 つの単位にバンドルするための方法です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-139">Helm is as a package manager for Kubernetes &mdash; a way to bundle Kubernetes objects into a single unit that you can publish, deploy, version, and update.</span></span>

<span data-ttu-id="85ca1-140">**Azure Monitor**。</span><span class="sxs-lookup"><span data-stu-id="85ca1-140">**Azure Monitor**.</span></span> <span data-ttu-id="85ca1-141">Azure Monitor は、メトリックやログ (ソリューションおよびアプリケーション テレメトリ内の Azure サービスのプラットフォーム メトリックを含む) を収集および格納します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-141">Azure Monitor collects and stores metrics and logs, including platform metrics for the Azure services in the solution and application telemetry.</span></span> <span data-ttu-id="85ca1-142">このデータは、アプリケーションを監視したり、アラートやダッシュボードを設定したり、障害の根本原因分析を実行したりするために使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-142">Use this data to monitor the application, set up alerts and dashboards, and perform root cause analysis of failures.</span></span> <span data-ttu-id="85ca1-143">Azure Monitor は、コントローラー、ノード、およびコンテナーからのメトリックや、コンテナー ログおよびマスター ノード ログを収集するために AKS と統合します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-143">Azure Monitor integrates with AKS to collect metrics from controllers, nodes, and containers, as well as container logs and master node logs.</span></span>

## <a name="design-considerations"></a><span data-ttu-id="85ca1-144">設計上の考慮事項</span><span class="sxs-lookup"><span data-stu-id="85ca1-144">Design considerations</span></span>

<span data-ttu-id="85ca1-145">この参照アーキテクチャはマイクロサービス アーキテクチャに重点を置いていますが、推奨されるプラクティスの多くは AKS 上で実行される他のワークロードにも適用されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-145">This reference architecture is focused on microservices architectures, although many of the recommended practices will apply to other workloads running on AKS.</span></span>

### <a name="microservices"></a><span data-ttu-id="85ca1-146">マイクロサービス</span><span class="sxs-lookup"><span data-stu-id="85ca1-146">Microservices</span></span>

<span data-ttu-id="85ca1-147">Kubernetes Service オブジェクトは、Kubernetes でマイクロサービスをモデル化するための自然な方法です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-147">The Kubernetes Service object is a natural way to model microservices in Kubernetes.</span></span> <span data-ttu-id="85ca1-148">マイクロサービスは、コードの疎結合で、かつ独立にデプロイ可能な単位です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-148">A microservice is a loosely coupled, independently deployable unit of code.</span></span> <span data-ttu-id="85ca1-149">マイクロサービスは通常、適切に定義された API 経由で通信し、何らかの形式のサービス検出によって検出できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-149">Microservices typically communicate through well-defined APIs, and are discoverable through some form of service discovery.</span></span> <span data-ttu-id="85ca1-150">Kubernetes Service オブジェクトは、次の要件に一致する一連の機能を提供します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-150">The Kubernetes Service object provides a set of capabilities that match these requirements:</span></span>

- <span data-ttu-id="85ca1-151">IP アドレス。</span><span class="sxs-lookup"><span data-stu-id="85ca1-151">IP address.</span></span> <span data-ttu-id="85ca1-152">Service オブジェクトは、ポッドのグループ (ReplicaSet) に静的内部 IP アドレスを提供します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-152">The Service object provides a static internal IP address for a group of pods (ReplicaSet).</span></span> <span data-ttu-id="85ca1-153">ポッドが作成されたり移動されたりしても、常に、この内部 IP アドレスでサービスに到達できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-153">As pods are created or moved around, the service is always reachable at this internal IP address.</span></span>

- <span data-ttu-id="85ca1-154">負荷分散。</span><span class="sxs-lookup"><span data-stu-id="85ca1-154">Load balancing.</span></span> <span data-ttu-id="85ca1-155">サービスの IP アドレスに送信されたトラフィックは、ポッドに対して負荷分散されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-155">Traffic sent to the service's IP address is load balanced to the pods.</span></span> 

- <span data-ttu-id="85ca1-156">サービス検出。</span><span class="sxs-lookup"><span data-stu-id="85ca1-156">Service discovery.</span></span> <span data-ttu-id="85ca1-157">サービスには、Kubernetes DNS サービスによって内部の DNS エントリが割り当てられます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-157">Services are assigned internal DNS entries by the Kubernetes DNS service.</span></span> <span data-ttu-id="85ca1-158">つまり、API ゲートウェイは、DNS 名を使用してバックエンド サービスを呼び出すことができます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-158">That means the API gateway can call a backend service using the DNS name.</span></span> <span data-ttu-id="85ca1-159">サービス間の通信にも同じメカニズムを使用できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-159">The same mechanism can be used for service-to-service communication.</span></span> <span data-ttu-id="85ca1-160">DNS エントリは名前空間ごとに整理されるため、名前空間が境界付けられたコンテキストに対応している場合は、サービスの DNS 名がアプリケーション ドメインに自然にマッピングされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-160">The DNS entries are organized by namespace, so if your namespaces correspond to bounded contexts, then the DNS name for a service will map naturally to the application domain.</span></span>

<span data-ttu-id="85ca1-161">次の図は、サービスとポッドの関係の概念を示しています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-161">The following diagram show the conceptual relation between services and pods.</span></span> <span data-ttu-id="85ca1-162">エンドポイントの IP アドレスおよびポートへの実際のマッピングは、Kubernetes のネットワーク プロキシである kube-proxy によって実行されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-162">The actual mapping to endpoint IP addresses and ports is done by kube-proxy, the Kubernetes network proxy.</span></span>

![サービスとポッド](./_images/aks-services.png)

### <a name="api-gateway"></a><span data-ttu-id="85ca1-164">API ゲートウェイ</span><span class="sxs-lookup"><span data-stu-id="85ca1-164">API Gateway</span></span>

<span data-ttu-id="85ca1-165">*API ゲートウェイ*は、外部クライアントとマイクロサービスの間に位置するゲートウェイです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-165">An *API gateway* is a gateway that sits between external clients and the microservices.</span></span> <span data-ttu-id="85ca1-166">これは、要求をクライアントからマイクロサービスにルーティングするリバース プロキシとして機能します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-166">It acts as a reverse proxy, routing requests from clients to microservices.</span></span> <span data-ttu-id="85ca1-167">さらに、認証、SSL 終了、レート制限などのさまざまな横断的タスクを実行できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-167">It may also perform various cross-cutting tasks such as authentication, SSL termination, and rate limiting.</span></span> 

<span data-ttu-id="85ca1-168">ゲートウェイによって提供される機能は、次のようにグループ化できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-168">Functionality provided by a gateway can be grouped as follows:</span></span>

- <span data-ttu-id="85ca1-169">[ゲートウェイ ルーティング](../../patterns/gateway-routing.md): クライアント要求の適切なバックエンド サービスへのルーティング。</span><span class="sxs-lookup"><span data-stu-id="85ca1-169">[Gateway Routing](../../patterns/gateway-routing.md): Routing client requests to the right backend services.</span></span> <span data-ttu-id="85ca1-170">これはクライアントに単一のエンドポイントを提供し、サービスからクライアントを分離するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-170">This provides a single endpoint for clients, and helps to decouple clients from services.</span></span>

- <span data-ttu-id="85ca1-171">[ゲートウェイ集約](../../patterns/gateway-aggregation.md): クライアントとバックエンドの間の頻繁な通信を削減するための、複数の要求の 1 つの要求への集約。</span><span class="sxs-lookup"><span data-stu-id="85ca1-171">[Gateway Aggregation](../../patterns/gateway-aggregation.md): Aggregation of multiple requests into a single request, to reduce chattiness between the client and the backend.</span></span>

- <span data-ttu-id="85ca1-172">[ゲートウェイ オフロード](../../patterns/gateway-offloading.md)。</span><span class="sxs-lookup"><span data-stu-id="85ca1-172">[Gateway Offloading](../../patterns/gateway-offloading.md).</span></span> <span data-ttu-id="85ca1-173">ゲートウェイは、SSL 終了、認証、IP ホワイトリスト登録、クライアントのレート制限 (調整) など、バックエンド サービスから機能をオフロードできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-173">A gateway can offload functionality from the backend services, such as SSL termination, authentication, IP whitelisting, or client rate limiting (throttling).</span></span>

<span data-ttu-id="85ca1-174">API ゲートウェイは、一般的な[マイクロサービスの設計パターン](https://microservices.io/patterns/apigateway.html)です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-174">API gateways are a general [microservices design pattern](https://microservices.io/patterns/apigateway.html).</span></span> <span data-ttu-id="85ca1-175">これらは、いくつかの異なるテクノロジを使用して実装できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-175">They can be implemented using a number of different technologies.</span></span> <span data-ttu-id="85ca1-176">おそらく、最も一般的な実装は、クラスター内に Nginx、HAProxy、Traefik などのエッジ ルーターまたはリバース プロキシをデプロイすることです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-176">Probably the most common implementation is to deploy an edge router or reverse proxy, such as Nginx, HAProxy, or Traefik, inside the cluster.</span></span> 

<span data-ttu-id="85ca1-177">その他のオプションには、次のものが含まれます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-177">Other options include:</span></span>

- <span data-ttu-id="85ca1-178">どちらもクラスターの外部に存在するマネージド サービスである Azure Application Gateway または Azure API-Management、あるいはその両方。</span><span class="sxs-lookup"><span data-stu-id="85ca1-178">Azure Application Gateway and/or Azure API-Management, which are both managed services that reside outside of the cluster.</span></span> <span data-ttu-id="85ca1-179">Application Gateway イングレス コントローラーは現在、ベータ版です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-179">An Application Gateway Ingress Controller is currently in beta.</span></span>

- <span data-ttu-id="85ca1-180">Azure Functions プロキシ。</span><span class="sxs-lookup"><span data-stu-id="85ca1-180">Azure Functions Proxies.</span></span> <span data-ttu-id="85ca1-181">プロキシは要求や応答を変更したり、URL に基づいて要求をルーティングしたりできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-181">Proxies can modify requests and responses and route requests based on URL.</span></span>

<span data-ttu-id="85ca1-182">Kubernetes **イングレス** リソースの種類は、プロキシ サーバーの構成設定を抽象化します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-182">The Kubernetes **Ingress** resource type abstracts the configuration settings for a proxy server.</span></span> <span data-ttu-id="85ca1-183">これはイングレス コントローラーと組み合わせて機能し、これにより、イングレスの基礎となる実装が提供されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-183">It works in conjunction with an ingress controller, which provides the underlying implementation of the Ingress.</span></span> <span data-ttu-id="85ca1-184">特に、Nginx、HAProxy、Traefik、および Application Gateway (プレビュー) 用のイングレス コントローラーが存在します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-184">There are ingress controllers for Nginx, HAProxy, Traefik, and Application Gateway (preview), among others.</span></span>

<span data-ttu-id="85ca1-185">イングレス コントローラーは、プロキシ サーバーの構成を処理します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-185">The ingress controller handles configuring the proxy server.</span></span> <span data-ttu-id="85ca1-186">多くの場合は、エキスパートでなければ調整が難しい複雑な構成ファイルが必要になるため、イングレス コントローラーは優れた抽象化です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-186">Often these require complex configuration files, which can be hard to tune if you aren't an expert, so the ingress controller is a nice abstraction.</span></span> <span data-ttu-id="85ca1-187">さらに、イングレス コントローラーは Kubernetes API にアクセスできるため、ルーティングや負荷分散に関するインテリジェントな決定を行うことができます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-187">In addition, the Ingress Controller has access to the Kubernetes API, so it can make intelligent decisions about routing and load balancing.</span></span> <span data-ttu-id="85ca1-188">たとえば、Nginx イングレス コントローラーは kube-proxy ネットワーク プロキシをバイパスします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-188">For example, the Nginx ingress controller bypasses the kube-proxy network proxy.</span></span>

<span data-ttu-id="85ca1-189">これに対して、設定に対する完全な制御が必要な場合は、この抽象化をバイパスしてプロキシ サーバーを手動で構成することもできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-189">On the other hand, if you need complete control over the settings, you may want to bypass this abstraction and configure the proxy server manually.</span></span> 

<span data-ttu-id="85ca1-190">リバース プロキシ サーバーは潜在的なボトルネックまたは単一障害点であるため、高可用性のためには、常に少なくとも 2 つのレプリカをデプロイします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-190">A reverse proxy server is a potential bottleneck or single point of failure, so always deploy at least two replicas for high availability.</span></span>

### <a name="data-storage"></a><span data-ttu-id="85ca1-191">データ ストレージ</span><span class="sxs-lookup"><span data-stu-id="85ca1-191">Data storage</span></span>

<span data-ttu-id="85ca1-192">マイクロサービス アーキテクチャでは、サービスはデータ ストレージを共有すべきではありません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-192">In a microservices architecture, services should not share data storage.</span></span> <span data-ttu-id="85ca1-193">各サービスは、サービス間の隠れた依存関係を回避するために、独自のプライベート データを個別の論理ストレージ内に所有する必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-193">Each service should own its own private data in a separate logical storage, to avoid hidden dependencies among services.</span></span> <span data-ttu-id="85ca1-194">これは、サービスが基礎となる同じデータ スキーマを共有している場合に発生することのある、サービス間の意図しない結合を回避するためです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-194">The reason is to avoid unintentional coupling between services, which can happen when services share the same underlying data schemas.</span></span> <span data-ttu-id="85ca1-195">サービスはまた、独自のデータ ストアを管理する場合、特定の要件に適したデータ ストアを使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-195">Also, when services manage their own data stores, they can use the right data store for their particular requirements.</span></span> <span data-ttu-id="85ca1-196">詳細については、「[マイクロサービスの設計: データに関する考慮事項](/azure/architecture/microservices/data-considerations)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-196">For more information, see [Designing microservices: Data considerations](/azure/architecture/microservices/data-considerations).</span></span>

<span data-ttu-id="85ca1-197">データがノードに結合されるため、永続データをローカルのクラスター ストレージに格納することは避けてください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-197">Avoid storing persistent data in local cluster storage, because that ties the data to the node.</span></span> <span data-ttu-id="85ca1-198">代わりに、次のことを行います。</span><span class="sxs-lookup"><span data-stu-id="85ca1-198">Instead,</span></span> 

- <span data-ttu-id="85ca1-199">Azure SQL Database や Cosmos DB などの外部サービスを使用するか、*または*</span><span class="sxs-lookup"><span data-stu-id="85ca1-199">Use an external service such as Azure SQL Database or Cosmos DB, *or*</span></span>

- <span data-ttu-id="85ca1-200">Azure ディスクまたは Azure Files を使用して永続ボリュームをマウントします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-200">Mount a persistent volume using Azure Disks or Azure Files.</span></span> <span data-ttu-id="85ca1-201">複数のポッドで同じボリュームを共有する必要がある場合は、Azure Files を使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-201">Use Azure Files if the same volume needs to be shared by multiple pods.</span></span>

### <a name="namespaces"></a><span data-ttu-id="85ca1-202">名前空間</span><span class="sxs-lookup"><span data-stu-id="85ca1-202">Namespaces</span></span>

<span data-ttu-id="85ca1-203">クラスター内のサービスを整理するには、名前空間を使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-203">Use namespaces to organize services within the cluster.</span></span> <span data-ttu-id="85ca1-204">Kubernetes クラスター内のオブジェクトはすべて、名前空間に属します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-204">Every object in a Kubernetes cluster belongs to a namespace.</span></span> <span data-ttu-id="85ca1-205">既定では、新しいオブジェクトを作成すると、そのオブジェクトは `default` 名前空間に移動します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-205">By default, when you create a new object, it goes into the `default` namespace.</span></span> <span data-ttu-id="85ca1-206">ただし、クラスター内のリソースを整理しやすくするために、わかりやすい名前空間を作成することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-206">But it's a good practice to create namespaces that are more descriptive to help organize the resources in the cluster.</span></span>

<span data-ttu-id="85ca1-207">まず、名前空間は名前付けの衝突を防止するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-207">First, namespaces help prevent naming collisions.</span></span> <span data-ttu-id="85ca1-208">複数のチームが (数百ある可能性がある) マイクロサービスを同じクラスターにデプロイするとき、それらがすべて同じ名前空間に移動すると管理が困難になります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-208">When multiple teams deploy microservices into the same cluster, with possibly hundreds of microservices, it gets hard to manage if they all go into the same namespace.</span></span> <span data-ttu-id="85ca1-209">さらに、名前空間では、次のことが可能になります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-209">In addition, namespaces allow you to:</span></span>

- <span data-ttu-id="85ca1-210">名前空間に割り当てられたすべてのポッドが名前空間のリソースのクォータを超えることがないように、その名前空間にリソース制約を適用する。</span><span class="sxs-lookup"><span data-stu-id="85ca1-210">Apply resource constraints to a namespace, so that the total set of pods assigned to that namespace cannot exceed the resource quota of the namespace.</span></span>

- <span data-ttu-id="85ca1-211">名前空間レベルでポリシーを適用する (RBAC やセキュリティ ポリシーを含む)。</span><span class="sxs-lookup"><span data-stu-id="85ca1-211">Apply policies at the namespace level, including RBAC and security policies.</span></span>

<span data-ttu-id="85ca1-212">マイクロサービス アーキテクチャでは、マイクロサービスを境界付けられたコンテキストに整理し、境界付けられたコンテキストごとに名前空間を作成することを考慮してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-212">For a microservices architecture, considering organizing the microservices into bounded contexts, and creating namespaces for each bounded context.</span></span> <span data-ttu-id="85ca1-213">たとえば、"受注処理" の境界付けられたコンテキストに関連したマイクロサービスはすべて、同じ名前空間に移動する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-213">For example, all microservices related to the "Order Fulfillment" bounded context could go into the same namespace.</span></span> <span data-ttu-id="85ca1-214">あるいは、開発チームごとに名前空間を作成します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-214">Alternatively, create a namespace for each development team.</span></span>

<span data-ttu-id="85ca1-215">ユーティリティ サービスをその独自の個別の名前空間に配置します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-215">Place utility services into their own separate namespace.</span></span> <span data-ttu-id="85ca1-216">たとえば、クラスターの監視には Elasticsearch または Prometheus を、Helm には Tiller をデプロイできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-216">For example, you might deploy Elasticsearch or Prometheus for cluster monitoring, or Tiller for Helm.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="85ca1-217">スケーラビリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="85ca1-217">Scalability considerations</span></span>

<span data-ttu-id="85ca1-218">Kubernetes は、次の 2 つのレベルでスケールアウトをサポートします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-218">Kubernetes supports scale-out at two levels:</span></span>

- <span data-ttu-id="85ca1-219">デプロイに割り当てられるポッドの数をスケール調整します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-219">Scale the number of pods allocated to a deployment.</span></span>
- <span data-ttu-id="85ca1-220">クラスターで使用できるコンピューティング リソースの合計を増やすために、クラスター内のノードをスケール調整します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-220">Scale the nodes in the cluster, to increase the total compute resources available to the cluster.</span></span>

<span data-ttu-id="85ca1-221">ポッドとノードは手動でスケールアウトできますが、高負荷のもとでサービスがリソース不足になる可能性を最小限に抑えるために、自動スケールを使用することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-221">Although you can scale out pods and nodes manually, we recommend using autoscaling, to minimize the chance that services will become resource starved under high load.</span></span> <span data-ttu-id="85ca1-222">自動スケール戦略では、ポッドとノードの両方を考慮に入れる必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-222">An autoscaling strategy must take both pods and nodes into account.</span></span> <span data-ttu-id="85ca1-223">ポッドだけをスケールアウトした場合、最終的にはノードのリソース制限に達します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-223">If you just scale out the pods, eventually you will reach the resource limits of the nodes.</span></span> 

### <a name="pod-autoscaling"></a><span data-ttu-id="85ca1-224">ポッドの自動スケール</span><span class="sxs-lookup"><span data-stu-id="85ca1-224">Pod autoscaling</span></span>

<span data-ttu-id="85ca1-225">ポッドの水平オートスケーラー (HPA) は、観察された CPU、メモリ、またはカスタム メトリックに基づいてポッドをスケール調整します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-225">The Horizontal Pod Autoscaler (HPA) scales pods based on observed CPU, memory, or custom metrics.</span></span> <span data-ttu-id="85ca1-226">ポッドの水平スケーリングを構成するには、ターゲットのメトリック (CPU の 70% など) とレプリカの最小および最大数を指定します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-226">To configure horizontal pod scaling, you specify a target metric (for example, 70% of CPU), and the minimum and maximum number of replicas.</span></span> <span data-ttu-id="85ca1-227">サービスをロード テストして、これらの数値を導き出す必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-227">You should load test your services to derive these numbers.</span></span>

<span data-ttu-id="85ca1-228">自動スケールの副作用は、スケールアウトおよびスケールイン イベントが発生すると、ポッドがより頻繁に作成または削除される可能性があることです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-228">A side-effect of autoscaling is that pods may be created or evicted more frequently, as scale-out and scale-in events happen.</span></span> <span data-ttu-id="85ca1-229">この影響を緩和するには、次のようにします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-229">To mitigate the effects of this:</span></span>

- <span data-ttu-id="85ca1-230">準備プローブを使用して、新しいポッドがトラフィックを受け付ける準備ができたら Kubernetes に認識されるようにします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-230">Use readiness probes to let Kubernetes know when a new pod is ready to accept traffic.</span></span>
- <span data-ttu-id="85ca1-231">ポッド中断バジェットを使用して、サービスから一度に削除できるポッドの数を制限します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-231">Use pod disruption budgets to limit how many pods can be evicted from a service at a time.</span></span>

### <a name="cluster-autoscaling"></a><span data-ttu-id="85ca1-232">クラスターの自動スケール</span><span class="sxs-lookup"><span data-stu-id="85ca1-232">Cluster autoscaling</span></span>

<span data-ttu-id="85ca1-233">クラスター オートスケーラーは、ノードの数をスケール調整します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-233">The cluster autoscaler scales the number of nodes.</span></span> <span data-ttu-id="85ca1-234">リソース制約のためにポッドをスケジュールできない場合、クラスター オートスケーラーはさらに多くのノードをプロビジョニングします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-234">If pods can't be scheduled because of resource constraints, the cluster autoscaler will provision more nodes.</span></span>  <span data-ttu-id="85ca1-235">(注: AKS とクラスター オートスケーラーの間の統合は現在、プレビューの段階です。)</span><span class="sxs-lookup"><span data-stu-id="85ca1-235">(Note: Integration between AKS and the cluster autoscaler is currently in preview.)</span></span>

<span data-ttu-id="85ca1-236">HPA が消費されている実際のリソースや実行中のポッドからのその他のメトリックを調べるのに対して、クラスター オートスケーラーは、まだスケジュールされていないポッドのためにノードをプロビジョニングします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-236">Whereas HPA looks at actual resources consumed or other metrics from running pods, the cluster autoscaler is provisioning nodes for pods that aren't scheduled yet.</span></span> <span data-ttu-id="85ca1-237">そのため、デプロイの Kubernetes ポッド仕様で指定されている要求されたリソースを調べます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-237">Therefore, it looks at the requested resources, as specified in the Kubernetes pod spec for a deployment.</span></span> <span data-ttu-id="85ca1-238">これらの値を微調整するには、ロード テストを使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-238">Use load testing to fine-tune these values.</span></span>

<span data-ttu-id="85ca1-239">クラスターを作成した後に VM サイズを変更することはできないため、クラスターの作成時にエージェント ノードの適切な VM サイズを選択するには、何らかの初期の容量計画を実行する必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-239">You can't change the VM size after you create the cluster, so you should do some initial capacity planning to choose an appropriate VM size for the agent nodes when you create the cluster.</span></span> 

## <a name="availability-considerations"></a><span data-ttu-id="85ca1-240">可用性に関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="85ca1-240">Availability considerations</span></span>

### <a name="health-probes"></a><span data-ttu-id="85ca1-241">正常性プローブ</span><span class="sxs-lookup"><span data-stu-id="85ca1-241">Health probes</span></span>

<span data-ttu-id="85ca1-242">Kubernetes では、ポッドが公開できる次の 2 種類の正常性プローブが定義されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-242">Kubernetes defines two types of health probe that a pod can expose:</span></span>

- <span data-ttu-id="85ca1-243">準備プローブ: ポッドが要求を受け付ける準備ができたかどうかを Kubernetes に通知します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-243">Readiness probe: Tells Kubernetes whether the pod is ready to accept requests.</span></span>

- <span data-ttu-id="85ca1-244">liveness probe: ポッドが削除され、新しいインスタンスが起動されるかどうかを Kubernetes に通知します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-244">Liveness probe: Tells Kubernetes whether a pod should be removed and a new instance started.</span></span>

<span data-ttu-id="85ca1-245">プローブについて考慮する場合は、Kubernetes でのサービスのしくみを思い出すことが有効です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-245">When thinking about probes, it's useful to recall how a service works in Kubernetes.</span></span> <span data-ttu-id="85ca1-246">サービスには、一連の (0 個以上の) ポッドに一致するラベル セレクターがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-246">A service has a label selector that matches a set of (zero or more) pods.</span></span> <span data-ttu-id="85ca1-247">Kubernetes は、そのセレクターに一致するポッドへのトラフィックを負荷分散します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-247">Kubernetes load balances traffic to the pods that match the selector.</span></span> <span data-ttu-id="85ca1-248">正常に起動され、正常な状態にあるポッドのみがトラフィックを受信します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-248">Only pods that started successfully and are healthy receive traffic.</span></span> <span data-ttu-id="85ca1-249">コンテナーがクラッシュした場合、Kubernetes はポッドを強制終了し、置き換えをスケジュールします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-249">If a container crashes, Kubernetes kills the pod and schedules a replacement.</span></span>

<span data-ttu-id="85ca1-250">ポッドが正常に起動されたにもかかわらず、そのポッドがトラフィックを受信する準備ができていない場合があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-250">Sometimes, a pod may not be ready to receive traffic, even though the pod started successfully.</span></span> <span data-ttu-id="85ca1-251">たとえば、コンテナーで実行されているアプリケーションがメモリにデータを読み込んだり、構成データを読み取ったりする初期化タスクが存在する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-251">For example, there may be initialization tasks, where the application running in the container loads things into memory or reads configuration data.</span></span> <span data-ttu-id="85ca1-252">ポッドが正常であるが、トラフィックを受信する準備ができていないことを示すには、準備プローブを定義します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-252">To indicate that a pod is healthy but not ready to receive traffic, define a readiness probe.</span></span> 

<span data-ttu-id="85ca1-253">liveness probe は、ポッドが引き続き実行中だが、異常であるため、リサイクルする必要がある場合を処理します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-253">Liveness probes handle the case where a pod is still running, but is unhealthy and should be recycled.</span></span> <span data-ttu-id="85ca1-254">たとえば、コンテナーが HTTP 要求を処理しているが、何らかの理由でハングアップしたとします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-254">For example, suppose that a container is serving HTTP requests but hangs for some reason.</span></span> <span data-ttu-id="85ca1-255">そのコンテナーはクラッシュしませんが、すべての要求の処理を停止しました。</span><span class="sxs-lookup"><span data-stu-id="85ca1-255">The container doesn't crash, but it has stopped serving any requests.</span></span> <span data-ttu-id="85ca1-256">HTTP liveness probe を定義した場合、このプローブは応答を停止し、ポッドを再起動するよう Kubernetes に通知します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-256">If you define an HTTP liveness probe, the probe will stop responding and that informs Kubernetes to restart the pod.</span></span>

<span data-ttu-id="85ca1-257">プローブを設計する場合の考慮事項のいくつかを次に示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-257">Here are some considerations when designing probes:</span></span>

- <span data-ttu-id="85ca1-258">コードの起動時間が長い場合は、その起動が完了する前に liveness probe が障害を報告するおそれがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-258">If your code has a long startup time, there is a danger that a liveness probe will report failure before the startup completes.</span></span> <span data-ttu-id="85ca1-259">これを防ぐには、プローブの起動を遅延させる initialDelaySeconds 設定を使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-259">To prevent this, use the initialDelaySeconds setting, which delays the probe from starting.</span></span>

- <span data-ttu-id="85ca1-260">ポッドが再起動によって正常な状態に復元される可能性がない限り、liveness probe は役立ちません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-260">A liveness probe doesn't help unless restarting the pod is likely to restore it to a healthy state.</span></span> <span data-ttu-id="85ca1-261">メモリ リークや予期しないデッドロックに対する緩和のために liveness probe を使用できますが、またすぐに障害が発生するポッドを再起動しても意味がありません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-261">You can use a liveness probe to mitigate against memory leaks or unexpected deadlocks, but there's no point in restarting a pod that's going to immediately fail again.</span></span>

- <span data-ttu-id="85ca1-262">依存サービスをチェックするために準備プローブが使用される場合があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-262">Sometimes readiness probes are used to check dependent services.</span></span> <span data-ttu-id="85ca1-263">たとえば、ポッドにデータベースへの依存関係がある場合は、liveness probe がデータベース接続をチェックすることがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-263">For example, if a pod has a dependency on a database, the liveness probe might check the database connection.</span></span> <span data-ttu-id="85ca1-264">ただし、このアプローチにより、予期しない問題が発生する場合があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-264">However, this approach can create unexpected problems.</span></span> <span data-ttu-id="85ca1-265">外部サービスが何らかの理由で一時的に使用できなくなることがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-265">An external service might be temporarily unavailable for some reason.</span></span> <span data-ttu-id="85ca1-266">それにより、サービス内のすべてのポッドで準備プローブが失敗し、それらがすべて負荷分散から削除されるため、連鎖的な障害の上流が生成されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-266">That will cause the readiness probe to fail for all the pods in your service, causing all of them to be removed from load balancing, and thus creating cascading failures upstream.</span></span> <span data-ttu-id="85ca1-267">より適切なアプローチとして、サービスが一時的な障害から正常に復旧できるように、サービス内に再試行処理を実装します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-267">A better approach is to implement retry handling within your service, so that your service can recover correctly from transient failures.</span></span>

### <a name="resource-constraints"></a><span data-ttu-id="85ca1-268">リソース制約</span><span class="sxs-lookup"><span data-stu-id="85ca1-268">Resource constraints</span></span>

<span data-ttu-id="85ca1-269">リソースの競合がサービスの可用性に影響を与える場合があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-269">Resource contention can affect the availability of a service.</span></span> <span data-ttu-id="85ca1-270">1 つのコンテナーがクラスター リソース (メモリと CPU) を占有できなくなるように、コンテナーのリソース制約を定義します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-270">Define resource constraints for containers, so that a single container cannot overwhelm the cluster resources (memory and CPU).</span></span> <span data-ttu-id="85ca1-271">スレッドやネットワーク接続などのコンテナー以外のリソースの場合は、[バルクヘッド パターン](/azure/architecture/patterns/bulkhead)を使用してリソースを分離することを考慮してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-271">For non-container resources, such as threads or network connections, consider using the [Bulkhead Pattern](/azure/architecture/patterns/bulkhead) to isolate resources.</span></span>

<span data-ttu-id="85ca1-272">名前空間に許可されるリソースの合計を制限するには、リソースのクォータを使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-272">Use resource quotas to limit the total resources allowed for a namespace.</span></span> <span data-ttu-id="85ca1-273">それにより、フロント エンドがバックエンド サービスをリソース不足にすることはなくなり、その逆も同様です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-273">That way, the front end can't starve the backend services for resources or vice-versa.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="85ca1-274">セキュリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="85ca1-274">Security considerations</span></span>

### <a name="role-based-access-control-rbac"></a><span data-ttu-id="85ca1-275">ロールベースのアクセス制御 (RBAC)</span><span class="sxs-lookup"><span data-stu-id="85ca1-275">Role based access control (RBAC)</span></span>

<span data-ttu-id="85ca1-276">Kubernetes と Azure のどちらにも、ロールベースのアクセス制御 (RBAC) のメカニズムがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-276">Kubernetes and Azure both have mechanisms for role-based access control (RBAC):</span></span>

- <span data-ttu-id="85ca1-277">Azure RBAC は、Azure でのリソースへのアクセス (新しい Azure リソースを作成する機能を含む) を制御します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-277">Azure RBAC controls access to resources in Azure, including the ability to create new Azure resources.</span></span> <span data-ttu-id="85ca1-278">アクセス許可は、ユーザー、グループ、またはサービス プリンシパルに割り当てることができます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-278">Permissions can be assigned to users, groups, or service principals.</span></span> <span data-ttu-id="85ca1-279">(サービス プリンシパルは、アプリケーションによって使用されるセキュリティ ID です。)</span><span class="sxs-lookup"><span data-stu-id="85ca1-279">(A service principal is a security identity used by applications.)</span></span>

- <span data-ttu-id="85ca1-280">Kubernetes RBAC は、Kubernetes API へのアクセス許可を制御します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-280">Kubernetes RBAC controls permissions to the Kubernetes API.</span></span> <span data-ttu-id="85ca1-281">たとえば、ポッドの作成やポッドの一覧表示は、RBAC によってユーザーに許可 (または拒否) できるアクションです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-281">For example, creating pods and listing pods are actions that can be authorized (or denied) to a user through RBAC.</span></span> <span data-ttu-id="85ca1-282">ユーザーに Kubernetes アクセス許可を割り当てるには、*ロール*と*ロール バインディング*を作成します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-282">To assign Kubernetes permissions to users, you create *roles* and *role bindings*:</span></span>

  - <span data-ttu-id="85ca1-283">ロールは、名前空間内で適用される一連のアクセス許可です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-283">A Role is a set of permissions that apply within a namespace.</span></span> <span data-ttu-id="85ca1-284">アクセス許可は、リソース (ポッドやデプロイなど) に対して動詞 (get、update、create、delete) として定義されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-284">Permissions are defined as verbs (get, update, create, delete) on resources (pods, deployments, etc.).</span></span>

  - <span data-ttu-id="85ca1-285">RoleBinding は、ロールにユーザーまたはグループを割り当てます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-285">A RoleBinding assigns users or groups to a Role.</span></span>

  - <span data-ttu-id="85ca1-286">また、ロールに似ているが、すべての名前空間にわたるクラスター全体に適用される ClusterRole オブジェクトも存在します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-286">There is also a ClusterRole object, which is like a Role but applies to the entire cluster, across all namespaces.</span></span> <span data-ttu-id="85ca1-287">ClusterRole にユーザーまたはグループを割り当てるには、ClusterRoleBinding を作成します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-287">To assign users or groups to a ClusterRole, create a ClusterRoleBinding.</span></span>

<span data-ttu-id="85ca1-288">AKS では、これらの 2 つの RBAC メカニズムが統合されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-288">AKS integrates these two RBAC mechanisms.</span></span> <span data-ttu-id="85ca1-289">AKS クラスターを作成するとき、そのクラスターを、ユーザー認証に Azure AD を使用するように構成できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-289">When you create an AKS cluster, you can configure it to use Azure AD for user authentication.</span></span> <span data-ttu-id="85ca1-290">これを設定する方法の詳細については、「[Azure Active Directory と Azure Kubernetes Service を統合する](/azure/aks/aad-integration)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-290">For details on how to set this up, see [Integrate Azure Active Directory with Azure Kubernetes Service](/azure/aks/aad-integration).</span></span>

<span data-ttu-id="85ca1-291">これが構成された後、Kubernetes API に (たとえば、kubectl 経由で) アクセスしようとするユーザーは、自分の Azure AD 資格情報を使用してサインインする必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-291">Once this is configured, a user who wants to access the Kubernetes API (for example, through kubectl) must sign in using their Azure AD credentials.</span></span>

<span data-ttu-id="85ca1-292">既定では、Azure AD ユーザーはクラスターにアクセスできません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-292">By default, an Azure AD user has no access to the cluster.</span></span> <span data-ttu-id="85ca1-293">アクセス権を付与するには、クラスター管理者が、Azure AD ユーザーまたはグループを参照する RoleBindings を作成します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-293">To grant access, the cluster administrator creates RoleBindings that refer to Azure AD users or groups.</span></span> <span data-ttu-id="85ca1-294">ユーザーに特定の操作のアクセス許可がない場合、これは失敗します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-294">If a user doesn't have permissions for a particular operation, it will fail.</span></span>

<span data-ttu-id="85ca1-295">ユーザーに既定でアクセス権がない場合、そもそも、クラスター管理者はロール バインディングを作成するためのアクセス許可をどのように取得するのでしょうか。</span><span class="sxs-lookup"><span data-stu-id="85ca1-295">If users have no access by default, how does the cluster admin have permission to create the role bindings in the first place?</span></span> <span data-ttu-id="85ca1-296">AKS クラスターには、実際には、Kubernetes API サーバーを呼び出すための資格情報としてクラスター ユーザーとクラスター管理者の 2 種類があります。クラスター管理者の資格情報は、クラスターへのフル アクセスを付与します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-296">An AKS cluster actually has two types of credentials for calling the Kubernetes API server: cluster user and cluster admin. The cluster admin credentials grant full access to the cluster.</span></span> <span data-ttu-id="85ca1-297">Azure CLI コマンド `az aks get-credentials --admin` はクラスター管理者の資格情報をダウンロードし、それを kubeconfig ファイルに保存します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-297">The Azure CLI command `az aks get-credentials --admin` downloads the cluster admin credentials and saves them into your kubeconfig file.</span></span> <span data-ttu-id="85ca1-298">クラスター管理者は、この kubeconfig を使用してロールとロール バインディングを作成できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-298">The cluster administrator can use this kubeconfig to create roles and role bindings.</span></span>

<span data-ttu-id="85ca1-299">クラスター管理者の資格情報は非常に強力であるため、Azure RBAC を使用して、それへのアクセスを制限します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-299">Because the cluster admin credentials are so powerful, use Azure RBAC to restrict access to them:</span></span>

- <span data-ttu-id="85ca1-300">"Azure Kubernetes Service クラスター管理者ロール" には、クラスター管理者の資格情報をダウンロードするためのアクセス許可があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-300">The "Azure Kubernetes Service Cluster Admin Role" has permission to download the cluster admin credentials.</span></span> <span data-ttu-id="85ca1-301">このロールにはクラスター管理者のみを割り当てる必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-301">Only cluster administrators should be assigned to this role.</span></span>

- <span data-ttu-id="85ca1-302">"Azure Kubernetes Service クラスター ユーザー ロール" には、クラスター ユーザーの資格情報をダウンロードするためのアクセス許可があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-302">The "Azure Kubernetes Service Cluster User Role" has permission to download the cluster user credentials.</span></span> <span data-ttu-id="85ca1-303">このロールには管理者以外のユーザーを割り当てることができます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-303">Non-admin users can be assigned to this role.</span></span> <span data-ttu-id="85ca1-304">このロールは、クラスター内の Kubernetes リソースに対する特定のどのアクセス許可も提供しません。ユーザーが API サーバーに接続できるようにするだけです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-304">This role does not give any particular permissions on Kubernetes resources inside the cluster &mdash; it just allows a user to connect to the API server.</span></span> 

<span data-ttu-id="85ca1-305">RBAC ポリシー (Kubernetes と Azure の両方) を定義する場合は、組織内のロールについて考慮してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-305">When you define your RBAC policies (both Kubernetes and Azure), think about the roles in your organization:</span></span>

- <span data-ttu-id="85ca1-306">誰が AKS クラスターを作成または削除したり、管理者の資格情報をダウンロードしたりできますか。</span><span class="sxs-lookup"><span data-stu-id="85ca1-306">Who can create or delete an AKS cluster and download the admin credentials?</span></span>
- <span data-ttu-id="85ca1-307">誰がクラスターを管理できますか。</span><span class="sxs-lookup"><span data-stu-id="85ca1-307">Who can administer a cluster?</span></span>
- <span data-ttu-id="85ca1-308">誰が名前空間内のリソースを作成または更新できますか。</span><span class="sxs-lookup"><span data-stu-id="85ca1-308">Who can create or update resources within a namespace?</span></span>

<span data-ttu-id="85ca1-309">ClusterRoles と ClusterRoleBindings ではなく、Roles と RoleBindings を使用して、Kubernetes RBAC アクセス許可のスコープを名前空間ごとに設定することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-309">It's a good practice to scope Kubernetes RBAC permissions by namespace, using Roles and RoleBindings, rather than ClusterRoles and ClusterRoleBindings.</span></span>

<span data-ttu-id="85ca1-310">最後に、Azure リソース (ロード バランサー、ネットワーク、ストレージなど) を作成および管理するために AKS クラスターにはどのようなアクセス許可があるかという疑問があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-310">Finally, there is the question of what permissions the AKS cluster has to create and manage Azure resources, such as load balancers, networking, or storage.</span></span> <span data-ttu-id="85ca1-311">Azure API で自身を認証するために、クラスターは Azure AD サービス プリンシパルを使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-311">To authenticate itself with Azure APIs, the cluster uses an Azure AD service principal.</span></span> <span data-ttu-id="85ca1-312">クラスターを作成するときにサービス プリンシパルを指定しない場合は、サービス プリンシパルが自動的に作成されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-312">If you don't specify a service principal when you create the cluster, one is created automatically.</span></span> <span data-ttu-id="85ca1-313">ただし、最初にサービス プリンシパルを作成し、それに最小限の RBAC アクセス許可を割り当てることが良いセキュリティ対策です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-313">However, it's a good security practice to create the service principal first and assign the minimal RBAC permissions to it.</span></span> <span data-ttu-id="85ca1-314">詳細については、[Azure Kubernetes Service でのサービス プリンシパル](/azure/aks/kubernetes-service-principal)に関するページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-314">For more information, see [Service principals with Azure Kubernetes Service](/azure/aks/kubernetes-service-principal).</span></span>

### <a name="secrets-management-and-application-credentials"></a><span data-ttu-id="85ca1-315">シークレットの管理とアプリケーションの資格情報</span><span class="sxs-lookup"><span data-stu-id="85ca1-315">Secrets management and application credentials</span></span>

<span data-ttu-id="85ca1-316">アプリケーションやサービスには、多くの場合、Azure Storage や SQL Database などの外部サービスに接続できるようにするための資格情報が必要です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-316">Applications and services often need credentials that allow them to connect to external services such as Azure Storage or SQL Database.</span></span> <span data-ttu-id="85ca1-317">これらの資格情報を安全に保持し、漏洩させないことが課題になります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-317">The challenge is to keep these credentials safe and not leak them.</span></span> 

<span data-ttu-id="85ca1-318">Azure リソースの場合は、マネージド ID を使用するオプションがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-318">For Azure resources, one option is to use managed identities.</span></span> <span data-ttu-id="85ca1-319">マネージド ID の考え方は、アプリケーションまたはサービスが Azure AD に格納された ID を持ち、この ID を使用して Azure サービスに対して認証するというものです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-319">The idea of a managed identity is that an application or service has an identity stored in Azure AD, and uses this identity to authenticate with an Azure service.</span></span> <span data-ttu-id="85ca1-320">アプリケーションまたはサービスは、Azure AD で自身のために作成されたサービス プリンシパルを持ち、OAuth 2.0 トークンを使用して認証します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-320">The application or service has a Service Principal created for it in Azure AD, and authenticates using OAuth 2.0 tokens.</span></span> <span data-ttu-id="85ca1-321">実行中のプロセスが localhost アドレスを呼び出し、そのトークンを取得します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-321">The executing process calls a localhost address to get the token.</span></span> <span data-ttu-id="85ca1-322">そのため、どのパスワードまたは接続文字列も格納する必要がありません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-322">That way, you don't need to store any passwords or connection strings.</span></span> <span data-ttu-id="85ca1-323">[aad-pod-identity](https://github.com/Azure/aad-pod-identity) プロジェクトを使用して、個々のポッドに ID を割り当てることによって、AKS でマネージド ID を使用できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-323">You can use managed identities in AKS by assigning identities to individual pods, using the [aad-pod-identity](https://github.com/Azure/aad-pod-identity) project.</span></span>

<span data-ttu-id="85ca1-324">現在、マネージド ID を使用した認証をすべての Azure サービスがサポートしているわけではありません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-324">Currently, not all Azure services support authentication using managed identities.</span></span> <span data-ttu-id="85ca1-325">その一覧については、[Azure AD 認証をサポートしている Azure サービス](/azure/active-directory/managed-identities-azure-resources/services-support-msi)に関するページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-325">For a list, see [Azure services that support Azure AD authentication](/azure/active-directory/managed-identities-azure-resources/services-support-msi).</span></span>

<span data-ttu-id="85ca1-326">マネージド ID を使用した場合でも、マネージド ID をサポートしていない Azure サービス、サードパーティのサービス、API キーなどでは、何らかの資格情報やその他のアプリケーション シークレットの格納が必要になる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-326">Even with managed identities, you'll probably need to store some credentials or other application secrets, whether for Azure services that don't support managed identities, third-party services, API keys, and so on.</span></span> <span data-ttu-id="85ca1-327">シークレットを安全に格納するためのオプションのいくつかを次に示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-327">Here are some options for storing secrets securely:</span></span>

- <span data-ttu-id="85ca1-328">Azure Key Vault。</span><span class="sxs-lookup"><span data-stu-id="85ca1-328">Azure Key Vault.</span></span> <span data-ttu-id="85ca1-329">AKS では、1 つ以上のシークレットを Key Vault からボリュームとしてマウントできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-329">In AKS, you can mount one or more secrets from Key Vault as a volume.</span></span> <span data-ttu-id="85ca1-330">このボリュームは、Key Vault からシークレットを読み取ります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-330">The volume reads the secrets from Key Vault.</span></span> <span data-ttu-id="85ca1-331">ポッドはその後、これらのシークレットを通常のボリュームと同様に読み取ることができます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-331">The pod can then read the secrets just like a regular volume.</span></span> <span data-ttu-id="85ca1-332">詳細については、GitHub 上の [Kubernetes-KeyVault-FlexVolume](https://github.com/Azure/kubernetes-keyvault-flexvol) プロジェクトを参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-332">For more information, see the [Kubernetes-KeyVault-FlexVolume](https://github.com/Azure/kubernetes-keyvault-flexvol) project on GitHub.</span></span>

    <span data-ttu-id="85ca1-333">ポッドは、上で説明したポッド ID を使用して、または Azure AD サービス プリンシパルをクライアント シークレットと共に使用して自身を認証します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-333">The pod authenticates itself by using either a pod identity (described above) or by using an Azure AD Service Principal along with a client secret.</span></span> <span data-ttu-id="85ca1-334">その場合はクライアント シークレットが必要ないため、ポッド ID の使用が推奨されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-334">Using pod identities is recommended because the client secret isn't needed in that case.</span></span> 

- <span data-ttu-id="85ca1-335">HashiCorp Vault。</span><span class="sxs-lookup"><span data-stu-id="85ca1-335">HashiCorp Vault.</span></span> <span data-ttu-id="85ca1-336">Kubernetes アプリケーションは、Azure AD マネージド ID を使用して HashiCorp Vault に対して認証できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-336">Kubernetes applications can authenticate with HashiCorp Vault using Azure AD managed identities.</span></span> <span data-ttu-id="85ca1-337">[HashiCorp Vault と Azure Active Directory の統合](https://open.microsoft.com/2018/04/10/scaling-tips-hashicorp-vault-azure-active-directory/)に関するページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-337">See [HashiCorp Vault speaks Azure Active Directory](https://open.microsoft.com/2018/04/10/scaling-tips-hashicorp-vault-azure-active-directory/).</span></span> <span data-ttu-id="85ca1-338">Vault 自体は Kubernetes にデプロイできますが、アプリケーション クラスターから個別の専用クラスターで実行することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-338">You can deploy Vault itself to Kubernetes, but it's recommend to run it in a separate dedicated cluster from your application cluster.</span></span> 

- <span data-ttu-id="85ca1-339">Kubernetes シークレット。</span><span class="sxs-lookup"><span data-stu-id="85ca1-339">Kubernetes secrets.</span></span> <span data-ttu-id="85ca1-340">もう 1 つのオプションとして、単純に Kubernetes シークレットを使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-340">Another option is simply to use Kubernetes secrets.</span></span> <span data-ttu-id="85ca1-341">このオプションは構成するのが最も簡単ですが、課題もいくつかあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-341">This option is the easiest to configure but has some challenges.</span></span> <span data-ttu-id="85ca1-342">シークレットは、分散型キー値ストアである etcd に格納されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-342">Secrets are stored in etcd, which is a distributed key-value store.</span></span> <span data-ttu-id="85ca1-343">AKS は、[保存時の etcd を暗号化します](https://github.com/Azure/kubernetes-kms#azure-kubernetes-service-aks)。</span><span class="sxs-lookup"><span data-stu-id="85ca1-343">AKS [encrypts etcd at rest](https://github.com/Azure/kubernetes-kms#azure-kubernetes-service-aks).</span></span> <span data-ttu-id="85ca1-344">暗号化キーは Microsoft が管理します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-344">Microsoft manages the encryption keys.</span></span>

<span data-ttu-id="85ca1-345">HashiCorp Vault や Azure Key Vault などのシステムの使用には、次のようないくつかの利点があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-345">Using a system like HashiCorp Vault or Azure Key Vault provides several advantages, such as:</span></span>

- <span data-ttu-id="85ca1-346">シークレットの集中制御。</span><span class="sxs-lookup"><span data-stu-id="85ca1-346">Centralized control of secrets.</span></span>
- <span data-ttu-id="85ca1-347">すべてのシークレットが保存時に暗号化されることの保証。</span><span class="sxs-lookup"><span data-stu-id="85ca1-347">Ensuring that all secrets are encrypted at rest.</span></span>
- <span data-ttu-id="85ca1-348">キーの集中管理。</span><span class="sxs-lookup"><span data-stu-id="85ca1-348">Centralized key management.</span></span>
- <span data-ttu-id="85ca1-349">シークレットのアクセス制御。</span><span class="sxs-lookup"><span data-stu-id="85ca1-349">Access control of secrets.</span></span>
- <span data-ttu-id="85ca1-350">監査</span><span class="sxs-lookup"><span data-stu-id="85ca1-350">Auditing</span></span>

### <a name="pod-and-container-security"></a><span data-ttu-id="85ca1-351">ポッドとコンテナーのセキュリティ</span><span class="sxs-lookup"><span data-stu-id="85ca1-351">Pod and container security</span></span>

<span data-ttu-id="85ca1-352">この一覧が網羅的でないことは確かですが、ポッドとコンテナーをセキュリティ保護するための推奨されるプラクティスのいくつかを次に示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-352">This list is certainly not exhaustive, but here are some recommended practices for securing your pods and containers:</span></span> 

<span data-ttu-id="85ca1-353">コンテナーを特権モードで実行しないでください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-353">Don't run containers in privileged mode.</span></span> <span data-ttu-id="85ca1-354">特権モードは、ホスト上のすべてのデバイスにコンテナー アクセスを提供します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-354">Privileged mode gives a container access to all devices on the host.</span></span> <span data-ttu-id="85ca1-355">特権モードでのコンテナーの実行を禁止するようにポッドのセキュリティ ポリシーを設定できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-355">You can set Pod Security Policy to disallow containers from running in privileged mode.</span></span> 

<span data-ttu-id="85ca1-356">可能な場合は、コンテナー内での root としてのプロセスの実行を回避してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-356">When possible, avoid running processes as root inside containers.</span></span> <span data-ttu-id="85ca1-357">コンテナーではセキュリティの観点からの完全な分離は提供されないため、コンテナー プロセスを非特権ユーザーとして実行する方が適切です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-357">Containers do not provide complete isolation from a security standpoint, so it's better to run a container process as a non-privileged user.</span></span> 

<span data-ttu-id="85ca1-358">Azure Container Registry や Docker Trusted Registry などの、信頼できるプライベート レジストリにイメージを格納します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-358">Store images in a trusted private registry, such as Azure Container Registry or Docker Trusted Registry.</span></span> <span data-ttu-id="85ca1-359">Kubernetes のアドミッションの検証 webhook を使用して、ポッドが確実に、信頼できるレジストリからのみイメージをプルできるようにします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-359">Use a validating admission webhook in Kubernetes to ensure that pods can only pull images from the trusted registry.</span></span>

<span data-ttu-id="85ca1-360">Azure Marketplace から使用可能な Twistlock や Aqua などのスキャン ソリューションを使用して、既知の脆弱性がないかどうかイメージをスキャンします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-360">Scan images for known vulnerabilities, using a scanning solution such as Twistlock and Aqua, which are available through the Azure Marketplace.</span></span>

<span data-ttu-id="85ca1-361">Azure Container Registry の機能である ACR タスクを使用して、イメージへのパッチ適用を自動化します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-361">Automate image patching using ACR Tasks, a feature of Azure Container Registry.</span></span> <span data-ttu-id="85ca1-362">コンテナー イメージは、レイヤーから構築されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-362">A container image is built up from layers.</span></span> <span data-ttu-id="85ca1-363">基本レイヤーには、OS イメージとアプリケーション フレームワーク イメージ (ASP.NET Core や Node.js など) が含まれます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-363">The base layers include the OS image and application framework images, such as ASP.NET Core or Node.js.</span></span> <span data-ttu-id="85ca1-364">基本イメージは通常、アプリケーション開発者から上流で作成され、他のプロジェクト保守管理者によって保守されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-364">The base images are typically created upstream from the application developers, and are maintained by other project maintainers.</span></span> <span data-ttu-id="85ca1-365">上流でこれらのイメージにパッチが適用されたら、既知のセキュリティの脆弱性が残らないように、独自のイメージを更新、テスト、および再デプロイすることが重要です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-365">When these images are patched upstream, it's important to update, test, and redeploy your own images, so that you don't leave any known security vulnerabilities.</span></span> <span data-ttu-id="85ca1-366">ACR タスクは、このプロセスを自動化するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-366">ACR Tasks can help to automate this process.</span></span>

## <a name="deployment-cicd-considerations"></a><span data-ttu-id="85ca1-367">デプロイ (CI/CD) に関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="85ca1-367">Deployment (CI/CD) considerations</span></span>

<span data-ttu-id="85ca1-368">マイクロサービス アーキテクチャのための堅牢な CI/CD プロセスの目標のいくつかを次に示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-368">Here are some goals of a robust CI/CD process for a microservices architecture:</span></span>

- <span data-ttu-id="85ca1-369">各チームは、他のチームに影響を与えたり妨害したりすることなく、独立に所有するサービスを構築およびデプロイできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-369">Each team can build and deploy the services that it owns independently, without affecting or disrupting other teams.</span></span>

- <span data-ttu-id="85ca1-370">サービスの新しいバージョンは、運用環境にデプロイされる前に、検証のために開発/テスト/QA 環境にデプロイされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-370">Before a new version of a service is deployed to production, it gets deployed to dev/test/QA environments for validation.</span></span> <span data-ttu-id="85ca1-371">品質ゲートは、各段階で適用されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-371">Quality gates are enforced at each stage.</span></span>

- <span data-ttu-id="85ca1-372">サービスの新しいバージョンは、以前のバージョンと並行してデプロイできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-372">A new version of a service can be deployed side-by-side with the previous version.</span></span>

- <span data-ttu-id="85ca1-373">十分なアクセス制御ポリシーが設定されています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-373">Sufficient access control policies are in place.</span></span>

- <span data-ttu-id="85ca1-374">運用環境にデプロイされているコンテナー イメージを信頼できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-374">You can trust the container images that are deployed to production.</span></span>

### <a name="isolation-of-environments"></a><span data-ttu-id="85ca1-375">環境の分離</span><span class="sxs-lookup"><span data-stu-id="85ca1-375">Isolation of environments</span></span>

<span data-ttu-id="85ca1-376">開発、スモーク テスト、統合テスト、ロード テスト、最後に運用のための環境を含め、サービスをデプロイするための複数の環境が存在します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-376">You will have multiple environments where you deploy services, including environments for development, smoke testing, integration testing, load testing, and finally production.</span></span> <span data-ttu-id="85ca1-377">これらの環境には、あるレベルの分離が必要です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-377">These environments need some level of isolation.</span></span> <span data-ttu-id="85ca1-378">Kubernetes では、物理的な分離と論理的な分離のどちらかを選択できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-378">In Kubernetes, you have a choice between physical isolation and logical isolation.</span></span> <span data-ttu-id="85ca1-379">物理的な分離は、個別のクラスターにデプロイすることを示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-379">Physical isolation means deploying to separate clusters.</span></span> <span data-ttu-id="85ca1-380">論理的な分離では、先に説明したように、名前空間とポリシーを使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-380">Logical isolation makes use of namespaces and policies, as described earlier.</span></span>

<span data-ttu-id="85ca1-381">開発/テスト環境のための個別のクラスターと共に、専用の運用クラスターを作成することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-381">Our recommendation is to create a dedicated production cluster along with a separate cluster for your dev/test environments.</span></span> <span data-ttu-id="85ca1-382">開発/テスト クラスター内の環境を分離するには、論理的な分離を使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-382">Use logical isolation to separate environments within the dev/test cluster.</span></span> <span data-ttu-id="85ca1-383">開発/テスト クラスターにデプロイされたサービスには、ビジネス データを保持するデータ ストアへのアクセス権を与えるべきではありません。</span><span class="sxs-lookup"><span data-stu-id="85ca1-383">Services deployed to the dev/test cluster should never have access to data stores that hold business data.</span></span> 

### <a name="helm"></a><span data-ttu-id="85ca1-384">Helm</span><span class="sxs-lookup"><span data-stu-id="85ca1-384">Helm</span></span>

<span data-ttu-id="85ca1-385">Helm を使用してサービスの構築やデプロイを管理することを考慮してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-385">Consider using Helm to manage building and deploying services.</span></span> <span data-ttu-id="85ca1-386">CI/CD に役立つ Helm の機能には、次のものがあります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-386">Some of the features of Helm that help with CI/CD include:</span></span>

- <span data-ttu-id="85ca1-387">特定のマイクロサービスのすべての Kubernetes オブジェクトを 1 つの Helm グラフに整理します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-387">Organizing all of the Kubernetes objects for a particular microservice into a single Helm chart.</span></span>
- <span data-ttu-id="85ca1-388">一連の kubectl コマンドではなく、1 つの helm コマンドとしてグラフをデプロイします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-388">Deploying the chart as a single helm command, rather than a series of kubectl commands.</span></span>
- <span data-ttu-id="85ca1-389">以前のバージョンにロールバックする機能と共にセマンティック バージョニングを使用して、更新プログラムやリビジョンを追跡します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-389">Tracking updates and revisions, using semantic versioning, along with the ability to roll back to a previous version.</span></span>
- <span data-ttu-id="85ca1-390">多数のファイルにわたる情報の複製 (ラベルやセレクターなど) を回避するためにテンプレートを使用します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-390">The use of templates to avoid duplicating information, such as labels and selectors, across many files.</span></span>
- <span data-ttu-id="85ca1-391">グラフ間の依存関係を管理します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-391">Managing dependencies between charts.</span></span>
- <span data-ttu-id="85ca1-392">グラフを Helm リポジトリ (Azure Container Registry など) に発行し、それをビルド パイプラインと統合します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-392">Publishing charts to a Helm repository, such as Azure Container Registry, and integrating them with the build pipeline.</span></span>

<span data-ttu-id="85ca1-393">Helm リポジトリとしての Container Registry の使用の詳細については、「[アプリケーションのグラフに Helm リポジトリとして Azure Container Registry を使用する](/azure/container-registry/container-registry-helm-repos)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-393">For more information about using Container Registry as a Helm repository, see [Use Azure Container Registry as a Helm repository for your application charts](/azure/container-registry/container-registry-helm-repos).</span></span>

### <a name="cicd-workflow"></a><span data-ttu-id="85ca1-394">CI/CD ワークフロー</span><span class="sxs-lookup"><span data-stu-id="85ca1-394">CI/CD workflow</span></span>

<span data-ttu-id="85ca1-395">CI/CD ワークフローを作成する前に、コード ベースがどのように構造化され、管理されるかを理解しておく必要があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-395">Before creating a CI/CD workflow, you must know how the code base will be structured and managed.</span></span>

- <span data-ttu-id="85ca1-396">チームは、別個のリポジトリで作業するのか、単一のリポジトリで作業するのか。</span><span class="sxs-lookup"><span data-stu-id="85ca1-396">Do teams work in separate respositories or in a monorepo (single respository)?</span></span>
- <span data-ttu-id="85ca1-397">使用するブランチ戦略は何か。</span><span class="sxs-lookup"><span data-stu-id="85ca1-397">What is your branching strategy?</span></span>
- <span data-ttu-id="85ca1-398">運用環境にコードをプッシュできるのは誰か。</span><span class="sxs-lookup"><span data-stu-id="85ca1-398">Who can push code to production?</span></span> <span data-ttu-id="85ca1-399">リリース マネージャー ロールは存在するのか。</span><span class="sxs-lookup"><span data-stu-id="85ca1-399">Is there a release manager role?</span></span>

<span data-ttu-id="85ca1-400">単一リポジトリ アプローチのほうが支持されていますが、どちらにも長所と短所があります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-400">The monorepo approach has been gaining favor but there are advantages and disadvantages to both.</span></span>

| &nbsp; | <span data-ttu-id="85ca1-401">単一のリポジトリ</span><span class="sxs-lookup"><span data-stu-id="85ca1-401">Monorepo</span></span> | <span data-ttu-id="85ca1-402">複数のリポジトリ</span><span class="sxs-lookup"><span data-stu-id="85ca1-402">Multiple repos</span></span> |
|--------|----------|----------------|
| <span data-ttu-id="85ca1-403">**長所**</span><span class="sxs-lookup"><span data-stu-id="85ca1-403">**Advantages**</span></span> | <span data-ttu-id="85ca1-404">コードの共有</span><span class="sxs-lookup"><span data-stu-id="85ca1-404">Code sharing</span></span><br/><span data-ttu-id="85ca1-405">コードとツールの標準化が容易</span><span class="sxs-lookup"><span data-stu-id="85ca1-405">Easier to standardize code and tooling</span></span><br/><span data-ttu-id="85ca1-406">コードのリファクタリングが容易</span><span class="sxs-lookup"><span data-stu-id="85ca1-406">Easier to refactor code</span></span><br/><span data-ttu-id="85ca1-407">探しやすさ - コードの単一のビュー</span><span class="sxs-lookup"><span data-stu-id="85ca1-407">Discoverability - single view of the code</span></span><br/> | <span data-ttu-id="85ca1-408">各チームの所有権が明確</span><span class="sxs-lookup"><span data-stu-id="85ca1-408">Clear ownership per team</span></span><br/><span data-ttu-id="85ca1-409">マージ競合の可能性が少ない</span><span class="sxs-lookup"><span data-stu-id="85ca1-409">Potentially fewer merge conflicts</span></span><br/><span data-ttu-id="85ca1-410">マイクロサービスを強制的に分離するのに役立つ</span><span class="sxs-lookup"><span data-stu-id="85ca1-410">Helps to enforce decoupling of microservices</span></span> |
| <span data-ttu-id="85ca1-411">**課題**</span><span class="sxs-lookup"><span data-stu-id="85ca1-411">**Challenges**</span></span> | <span data-ttu-id="85ca1-412">共有コードの変更が複数のマイクロサービスに影響する可能性がある</span><span class="sxs-lookup"><span data-stu-id="85ca1-412">Changes to shared code can affect multiple microservices</span></span><br/><span data-ttu-id="85ca1-413">マージ競合の可能性が大きい</span><span class="sxs-lookup"><span data-stu-id="85ca1-413">Greater potential for merge conflicts</span></span><br/><span data-ttu-id="85ca1-414">大規模なコード ベースに合うようにツールを拡張する必要がある</span><span class="sxs-lookup"><span data-stu-id="85ca1-414">Tooling must scale to a large code base</span></span><br/><span data-ttu-id="85ca1-415">アクセス制御</span><span class="sxs-lookup"><span data-stu-id="85ca1-415">Access control</span></span><br/><span data-ttu-id="85ca1-416">複雑なデプロイ プロセス</span><span class="sxs-lookup"><span data-stu-id="85ca1-416">More complex deployment process</span></span> | <span data-ttu-id="85ca1-417">コードの共有が難しい</span><span class="sxs-lookup"><span data-stu-id="85ca1-417">Harder to share code</span></span><br/><span data-ttu-id="85ca1-418">コーディング規約の適用が難しい</span><span class="sxs-lookup"><span data-stu-id="85ca1-418">Harder to enforce coding standards</span></span><br/><span data-ttu-id="85ca1-419">依存関係の管理</span><span class="sxs-lookup"><span data-stu-id="85ca1-419">Dependency management</span></span><br/><span data-ttu-id="85ca1-420">コード ベースが拡散して探しにくい</span><span class="sxs-lookup"><span data-stu-id="85ca1-420">Diffuse code base, poor discoverability</span></span><br/><span data-ttu-id="85ca1-421">共有インフラストラクチャの欠如</span><span class="sxs-lookup"><span data-stu-id="85ca1-421">Lack of shared infrastructure</span></span>

<span data-ttu-id="85ca1-422">このセクションでは、次の前提に基づく可能な CI/CD ワークフローを示します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-422">In this section, we present a possible CI/CD workflow, based on the following assumptions:</span></span>

- <span data-ttu-id="85ca1-423">コード リポジトリは単一リポジトリであり、フォルダーがマイクロサービス別に整理されています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-423">The code repository is monorepo, with folders organized by microservice.</span></span>
- <span data-ttu-id="85ca1-424">チームのブランチ戦略は、[トランクベース開発](https://trunkbaseddevelopment.com/)に基づいています。</span><span class="sxs-lookup"><span data-stu-id="85ca1-424">The team's branching strategy is based on [trunk-based development](https://trunkbaseddevelopment.com/).</span></span>
- <span data-ttu-id="85ca1-425">チームは、[Azure Pipelines](/azure/devops/pipelines) を使用して CI/CD プロセスを実行します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-425">The team uses [Azure Pipelines](/azure/devops/pipelines) to run the CI/CD process.</span></span>
- <span data-ttu-id="85ca1-426">チームは、Azure Container Registry の[名前空間](/azure/container-registry/container-registry-best-practices#repository-namespaces)を使用して、運用するために承認されたイメージとまだテスト中であるイメージを分離します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-426">The team uses [namespaces](/azure/container-registry/container-registry-best-practices#repository-namespaces) in Azure Container Registry to isolate images that are approved for production from images that are still being tested.</span></span>

<span data-ttu-id="85ca1-427">この例では、開発者は Delivery Service と呼ばれるマイクロサービスを処理します </span><span class="sxs-lookup"><span data-stu-id="85ca1-427">In this example, a developer is working on a microservice called Delivery Service.</span></span> <span data-ttu-id="85ca1-428">(この名前は、[こちら](../../microservices/design/index.md#scenario)で説明されているリファレンス実装に由来します)。新機能の開発中に、開発者は、機能ブランチにコードをチェックインします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-428">(The name comes from the reference implementation described [here](../../microservices/design/index.md#scenario).) While developing a new feature, the developer checks code into a feature branch.</span></span>

![CI/CD ワークフロー](./_images/aks-cicd-1.png)

<span data-ttu-id="85ca1-430">このブランチにコミットをプッシュすると、マイクロサービス用の CI ビルドがトリガーされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-430">Pushing commits to this branch tiggers a CI build for the microservice.</span></span> <span data-ttu-id="85ca1-431">慣例により、機能ブランチは `feature/*` と名付けられます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-431">By convention, feature branches are named `feature/*`.</span></span> <span data-ttu-id="85ca1-432">[ビルド定義ファイル](/azure/devops/pipelines/yaml-schema)に、ブランチ名とソース パスでフィルター処理するトリガーが含まれます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-432">The [build definition file](/azure/devops/pipelines/yaml-schema) includes a trigger that filters by the branch name and the source path.</span></span> <span data-ttu-id="85ca1-433">このアプローチを使用して、各チームは、専用のビルド パイプラインを持つことができます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-433">Using this approach, each team can have its own build pipeline.</span></span>

```yaml
trigger:
  batch: true
  branches:
    include:
    - master
    - feature/*

    exclude:
    - feature/experimental/*

  paths:
     include:
     - /src/shipping/delivery/
```

<span data-ttu-id="85ca1-434">ワークフローのこの時点で、CI ビルドでは、いくつかの最小限のコードの検証が実行されます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-434">At this point in the workflow, the CI build runs some minimal code verification:</span></span>

1. <span data-ttu-id="85ca1-435">コードのビルド</span><span class="sxs-lookup"><span data-stu-id="85ca1-435">Build code</span></span>
1. <span data-ttu-id="85ca1-436">単体テストを実行する</span><span class="sxs-lookup"><span data-stu-id="85ca1-436">Run unit tests</span></span>

<span data-ttu-id="85ca1-437">ここでの考え方は、ビルド時間を短くして、開発者がすばやくフィードバックを取得できるようにすることです。</span><span class="sxs-lookup"><span data-stu-id="85ca1-437">The idea here is to keep the build times short so the developer can get quick feedback.</span></span> <span data-ttu-id="85ca1-438">開発者は、機能をマスターにマージする準備ができたら、PR を開きます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-438">When the feature is ready to merge into master, the developer opens a PR.</span></span> <span data-ttu-id="85ca1-439">これにより、いくつかの追加のチェックを実行する別の CI ビルドがトリガーされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-439">This triggers another CI build that performs some additional checks:</span></span>

1. <span data-ttu-id="85ca1-440">コードのビルド</span><span class="sxs-lookup"><span data-stu-id="85ca1-440">Build code</span></span>
1. <span data-ttu-id="85ca1-441">単体テストを実行する</span><span class="sxs-lookup"><span data-stu-id="85ca1-441">Run unit tests</span></span>
1. <span data-ttu-id="85ca1-442">ランタイム コンテナー イメージをビルドする</span><span class="sxs-lookup"><span data-stu-id="85ca1-442">Build the runtime container image</span></span>
1. <span data-ttu-id="85ca1-443">イメージの脆弱性スキャンを実行する</span><span class="sxs-lookup"><span data-stu-id="85ca1-443">Run vulnerability scans on the image</span></span>

![CI/CD ワークフロー](./_images/aks-cicd-2.png)

> [!NOTE]
> <span data-ttu-id="85ca1-445">Azure Repos では、ブランチを保護するための[ポリシー](/azure/devops/repos/git/branch-policies)を定義できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-445">In Azure Repos, you can define [policies](/azure/devops/repos/git/branch-policies) to protect branches.</span></span> <span data-ttu-id="85ca1-446">たとえば、マスターにマージするには、CI ビルドの成功に加え、承認者のサインオフが必要であることをポリシーで要求できます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-446">For example, the policy could require a successful CI build plus a sign-off from an approver in order to merge into master.</span></span>

<span data-ttu-id="85ca1-447">ある時点で、チームは、この Delivery サービスの新しいバージョンをデプロイする準備が整います。</span><span class="sxs-lookup"><span data-stu-id="85ca1-447">At some point, the team is ready to deploy a new version of the Delivery service.</span></span> <span data-ttu-id="85ca1-448">これを行うには、リリース マネージャーが `release/<microservice name>/<semver>` という名前付けパターンを使用して、マスターからブランチを作成します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-448">To do so, the release manager creates a branch from master with this naming pattern: `release/<microservice name>/<semver>`.</span></span> <span data-ttu-id="85ca1-449">たとえば、「 `release/delivery/v1.0.2` 」のように入力します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-449">For example, `release/delivery/v1.0.2`.</span></span>
<span data-ttu-id="85ca1-450">これにより、これまでのすべての手順に加え、以下を実行する完全な CI ビルドがトリガーされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-450">This triggers a full CI build that runs all the previous steps plus:</span></span>

1. <span data-ttu-id="85ca1-451">Docker イメージを Azure Container Registry にプッシュします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-451">Push the Docker image to Azure Container Registry.</span></span> <span data-ttu-id="85ca1-452">イメージには、ブランチ名から取得されたバージョン番号がタグ付けされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-452">The image is tagged with the version number taken from the branch name.</span></span>
2. <span data-ttu-id="85ca1-453">`helm package` を実行して、Helm チャートをパッケージ化します。</span><span class="sxs-lookup"><span data-stu-id="85ca1-453">Run `helm package` to package the Helm chart</span></span>
3. <span data-ttu-id="85ca1-454">`az acr helm push` を実行することで、Helm パッケージを Container Registry にプッシュします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-454">Push the Helm package to Container Registry by running `az acr helm push`.</span></span>

<span data-ttu-id="85ca1-455">このビルドが成功したと仮定すると、Azure Pipelines の[リリース パイプライン](/azure/devops/pipelines/release/what-is-release-management)を使用するデプロイ プロセスがトリガーされます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-455">Assuming this build succeeds, it triggers a deployment process using an Azure Pipelines [release pipeline](/azure/devops/pipelines/release/what-is-release-management).</span></span> <span data-ttu-id="85ca1-456">このパイプラインでは、</span><span class="sxs-lookup"><span data-stu-id="85ca1-456">This pipeline</span></span>

1. <span data-ttu-id="85ca1-457">`helm upgrade` を実行して、Helm チャートを QA 環境にデプロイします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-457">Run `helm upgrade` to deploy the Helm chart to a QA environment.</span></span>
1. <span data-ttu-id="85ca1-458">パッケージが運用環境に移動される前に、承認者がサインオフする。</span><span class="sxs-lookup"><span data-stu-id="85ca1-458">An approver signs off before the package moves to production.</span></span> <span data-ttu-id="85ca1-459">「[Release deployment control using approvals (承認を使用したリリース デプロイ制御)](/azure/devops/pipelines/release/approvals/approvals)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="85ca1-459">See [Release deployment control using approvals](/azure/devops/pipelines/release/approvals/approvals).</span></span>
1. <span data-ttu-id="85ca1-460">Docker イメージを Azure Container Registry 内の運用名前空間用に再度タグ付けします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-460">Re-tag the Docker image for the production namespace in Azure Container Registry.</span></span> <span data-ttu-id="85ca1-461">たとえば、現在のタグが `myrepo.azurecr.io/delivery:v1.0.2` の場合、運用タグは `myrepo.azurecr.io/prod/delivery:v1.0.2` になります。</span><span class="sxs-lookup"><span data-stu-id="85ca1-461">For example, if the current tag is `myrepo.azurecr.io/delivery:v1.0.2`, the production tag is `myrepo.azurecr.io/prod/delivery:v1.0.2`.</span></span>
1. <span data-ttu-id="85ca1-462">`helm upgrade` を実行して、Helm チャートを運用環境にデプロイします。</span><span class="sxs-lookup"><span data-stu-id="85ca1-462">Run `helm upgrade` to deploy the Helm chart to the production environment.</span></span>

![CI/CD ワークフロー](./_images/aks-cicd-3.png)

<span data-ttu-id="85ca1-464">単一リポジトリであっても、チームが短時間でデプロイできるように、これらのタスクのスコープを個々のマイクロサービスに設定できることを覚えておくことが重要です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-464">It's important to remember that even in a monorepo, these tasks can be scoped to individual microservices, so that teams can deploy with high velocity.</span></span> <span data-ttu-id="85ca1-465">このプロセスには、いくつか手動の手順があります。PR の承認、リリース ブランチの作成、および運用クラスターへのデプロイの承認です。</span><span class="sxs-lookup"><span data-stu-id="85ca1-465">There are some manual steps in the process: Approving PRs, creating release branches, and approving deployments into the production cluster.</span></span> <span data-ttu-id="85ca1-466">これらの手順は、ポリシーによって手動で行われます。組織が望むのであれば、完全に自動化することもできます。</span><span class="sxs-lookup"><span data-stu-id="85ca1-466">These steps are manual by policy &mdash; they could be completely automated if the organization prefers.</span></span>
