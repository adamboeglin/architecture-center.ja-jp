---
title: エンタープライズ ビジネス インテリジェンス
titleSuffix: Azure Reference Architectures
description: Azure を使用して、オンプレミスに保存されたリレーショナル データからビジネスの分析情報を獲得します。
author: MikeWasson
ms.date: 11/06/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: seodec18
ms.openlocfilehash: 14adb9de7f46c3196e893451859385d87212b375
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/20/2019
ms.locfileid: "58243863"
---
# <a name="enterprise-bi-in-azure-with-sql-data-warehouse"></a><span data-ttu-id="d7118-103">SQL Data Warehouse を使用した Azure のエンタープライズ向け BI</span><span class="sxs-lookup"><span data-stu-id="d7118-103">Enterprise BI in Azure with SQL Data Warehouse</span></span>

<span data-ttu-id="d7118-104">この参照アーキテクチャでは、オンプレミスの SQL Server データベースから SQL Data Warehouse にデータを移動し、そのデータを分析用に変換する[抽出、読み込み、変換 (ELT)](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) パイプラインを実装します。</span><span class="sxs-lookup"><span data-stu-id="d7118-104">This reference architecture implements an [extract, load, and transform (ELT)](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span>

<span data-ttu-id="d7118-105">このアーキテクチャのリファレンス実装は、[GitHub][github-folder] で入手できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-105">A reference implementation for this architecture is available on [GitHub][github-folder].</span></span>

![SQL Data Warehouse を使用した Azure のエンタープライズ向け BI のアーキテクチャ ダイアグラム](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="d7118-107">**シナリオ**:ある組織に、オンプレミスの SQL Server データベースに格納された大規模な OLTP データ セットがあります。</span><span class="sxs-lookup"><span data-stu-id="d7118-107">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="d7118-108">この組織では、SQL Data Warehouse を利用して Power BI を使った分析を行いたいと考えています。</span><span class="sxs-lookup"><span data-stu-id="d7118-108">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span>

<span data-ttu-id="d7118-109">この参照アーキテクチャは、1 回限りのジョブまたはオンデマンドのジョブ用に設計されています。</span><span class="sxs-lookup"><span data-stu-id="d7118-109">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="d7118-110">継続的に (毎時または毎日) データを移動する必要がある場合は、Azure Data Factory を使用して自動化されたワークフローを定義することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="d7118-110">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="d7118-111">Data Factory を使用する参照アーキテクチャについては、「[SQL Data Warehouse と Azure Data Factory を使用したエンタープライズ BI の自動化][adf-ra]」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-111">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="architecture"></a><span data-ttu-id="d7118-112">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="d7118-112">Architecture</span></span>

<span data-ttu-id="d7118-113">アーキテクチャは、次のコンポーネントで構成されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-113">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="d7118-114">データ ソース</span><span class="sxs-lookup"><span data-stu-id="d7118-114">Data source</span></span>

<span data-ttu-id="d7118-115">**SQL Server**。</span><span class="sxs-lookup"><span data-stu-id="d7118-115">**SQL Server**.</span></span> <span data-ttu-id="d7118-116">ソース データは、オンプレミスの SQL Server データベースにあります。</span><span class="sxs-lookup"><span data-stu-id="d7118-116">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="d7118-117">オンプレミス環境をシミュレートするために、このアーキテクチャのデプロイ スクリプトでは、SQL Server がインストールされた Azure の VM がプロビジョニングされます。</span><span class="sxs-lookup"><span data-stu-id="d7118-117">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="d7118-118">[Wide World Importers OLTP サンプル データベース][wwi]は、ソース データベースとして使用されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-118">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="d7118-119">インジェストとデータ ストレージ</span><span class="sxs-lookup"><span data-stu-id="d7118-119">Ingestion and data storage</span></span>

<span data-ttu-id="d7118-120">**Blob Storage**。</span><span class="sxs-lookup"><span data-stu-id="d7118-120">**Blob Storage**.</span></span> <span data-ttu-id="d7118-121">Blob Storage は、データを SQL Data Warehouse に読み込む前にコピーするためのステージング領域として使用されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-121">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="d7118-122">**Azure SQL Data Warehouse**。</span><span class="sxs-lookup"><span data-stu-id="d7118-122">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="d7118-123">[SQL Data Warehouse](/azure/sql-data-warehouse/) は、大規模なデータの分析を目的として設計された分散システムです。</span><span class="sxs-lookup"><span data-stu-id="d7118-123">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="d7118-124">超並列処理 (MPP) がサポートされているので、ハイパフォーマンス分析の実行に適しています。</span><span class="sxs-lookup"><span data-stu-id="d7118-124">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span>

### <a name="analysis-and-reporting"></a><span data-ttu-id="d7118-125">分析とレポート</span><span class="sxs-lookup"><span data-stu-id="d7118-125">Analysis and reporting</span></span>

<span data-ttu-id="d7118-126">**Azure Analysis Services**。</span><span class="sxs-lookup"><span data-stu-id="d7118-126">**Azure Analysis Services**.</span></span> <span data-ttu-id="d7118-127">[Analysis Services](/azure/analysis-services/) は、データ モデリング機能を提供するフル マネージド サービスです。</span><span class="sxs-lookup"><span data-stu-id="d7118-127">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="d7118-128">Analysis Services を使用して、ユーザーがクエリを実行できるセマンティック モデルを作成します。</span><span class="sxs-lookup"><span data-stu-id="d7118-128">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="d7118-129">Analysis Services は、BI ダッシュボードのシナリオで特に役立ちます。</span><span class="sxs-lookup"><span data-stu-id="d7118-129">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="d7118-130">このアーキテクチャでは、セマンティック モデルを処理するために Analysis Services によってデータ ウェアハウスからデータが読み取られ、ダッシュボードのクエリが効率的に処理されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-130">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="d7118-131">また、レプリカをスケールアウトしてクエリ処理を高速化することで、エラスティックなコンカレンシーもサポートします。</span><span class="sxs-lookup"><span data-stu-id="d7118-131">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="d7118-132">現在、Azure Analysis Services では表形式モデルをサポートしていますが、多次元モデルはサポートしていません。</span><span class="sxs-lookup"><span data-stu-id="d7118-132">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="d7118-133">表形式モデルではリレーショナル モデリング構造 (テーブル、列) を使用し、多次元モデルでは OLAP モデリング構造 (キューブ、ディメンション、メジャー) を使用します。</span><span class="sxs-lookup"><span data-stu-id="d7118-133">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="d7118-134">多次元モデルが必要な場合は、SQL Server Analysis Services (SSAS) を使用します。</span><span class="sxs-lookup"><span data-stu-id="d7118-134">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="d7118-135">詳細については、「[テーブル ソリューションと多次元ソリューションの比較](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-135">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="d7118-136">**Power BI**。</span><span class="sxs-lookup"><span data-stu-id="d7118-136">**Power BI**.</span></span> <span data-ttu-id="d7118-137">Power BI は、データを分析してビジネスの分析情報を得る一連のビジネス分析ツールです。</span><span class="sxs-lookup"><span data-stu-id="d7118-137">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="d7118-138">このアーキテクチャでは、Analysis Services に格納されたセマンティック モデルに対してクエリが実行されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-138">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="d7118-139">Authentication</span><span class="sxs-lookup"><span data-stu-id="d7118-139">Authentication</span></span>

<span data-ttu-id="d7118-140">**Azure Active Directory (Azure AD)** では、Power BI から Analysis Services サーバーに接続するユーザーの認証が行われます。</span><span class="sxs-lookup"><span data-stu-id="d7118-140">**Azure Active Directory (Azure AD)** authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="d7118-141">データ パイプライン</span><span class="sxs-lookup"><span data-stu-id="d7118-141">Data pipeline</span></span>

<span data-ttu-id="d7118-142">この参照アーキテクチャでは、[WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) サンプル データベースをデータ ソースとして使用します。</span><span class="sxs-lookup"><span data-stu-id="d7118-142">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="d7118-143">データ パイプラインには次のステージがあります。</span><span class="sxs-lookup"><span data-stu-id="d7118-143">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="d7118-144">SQL Server からフラット ファイルにデータをエクスポートする (bcp ユーティリティ)。</span><span class="sxs-lookup"><span data-stu-id="d7118-144">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="d7118-145">フラット ファイルを Azure Blob Storage にコピーする (AzCopy)。</span><span class="sxs-lookup"><span data-stu-id="d7118-145">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="d7118-146">SSQL Data Warehouse にデータを読み込む (PolyBase)。</span><span class="sxs-lookup"><span data-stu-id="d7118-146">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="d7118-147">データをスター スキーマに変換する (T-SQL)。</span><span class="sxs-lookup"><span data-stu-id="d7118-147">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="d7118-148">Analysis Services にセマンティック モデルを読み込みます (SQL Server Data Tools)。</span><span class="sxs-lookup"><span data-stu-id="d7118-148">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![エンタープライズ向け BI パイプラインのダイアグラム](./images/enterprise-bi-sqldw-pipeline.png)

> [!NOTE]
> <span data-ttu-id="d7118-150">手順 1 から 3 については、Redgate の Data Platform Studio を使用することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-150">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="d7118-151">Data Platform Studio では、最も適切な互換性修正プログラムと最適化が適用されるため、SQL Data Warehouse をごく手軽に使い始めることができます。</span><span class="sxs-lookup"><span data-stu-id="d7118-151">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="d7118-152">詳細については、[Redgate Data Platform Studio を使用したデータの読み込み](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate)に関する記事をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-152">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span>
>

<span data-ttu-id="d7118-153">以下のセクションでは、これらのステージについて詳しく説明します。</span><span class="sxs-lookup"><span data-stu-id="d7118-153">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="d7118-154">SQL Server からデータをエクスポートする</span><span class="sxs-lookup"><span data-stu-id="d7118-154">Export data from SQL Server</span></span>

<span data-ttu-id="d7118-155">[bcp](/sql/tools/bcp-utility) (一括コピー プログラム) ユーティリティを使用すると、SQL テーブルからフラット テキスト ファイルを迅速に作成できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-155">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="d7118-156">この手順では、エクスポートする列を選択しますが、データは変換しません。</span><span class="sxs-lookup"><span data-stu-id="d7118-156">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="d7118-157">データ変換は、SQL Data Warehouse で実行する必要があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-157">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="d7118-158">**推奨事項:**</span><span class="sxs-lookup"><span data-stu-id="d7118-158">**Recommendations:**</span></span>

<span data-ttu-id="d7118-159">運用環境でのリソースの競合を最小限に抑えるために、可能であれば、データ抽出をピーク外の時間帯にスケジュールします。</span><span class="sxs-lookup"><span data-stu-id="d7118-159">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span>

<span data-ttu-id="d7118-160">データベース サーバーで bcp を実行しないようにしてください。</span><span class="sxs-lookup"><span data-stu-id="d7118-160">Avoid running bcp on the database server.</span></span> <span data-ttu-id="d7118-161">代わりに、別のコンピューターから実行します。</span><span class="sxs-lookup"><span data-stu-id="d7118-161">Instead, run it from another machine.</span></span> <span data-ttu-id="d7118-162">ファイルをローカル ドライブに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="d7118-162">Write the files to a local drive.</span></span> <span data-ttu-id="d7118-163">同時書き込みを処理できるだけの十分な I/O リソースがあることを確認してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-163">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="d7118-164">最適なパフォーマンスを得るために、専用の高速ストレージ ドライブにファイルをエクスポートします。</span><span class="sxs-lookup"><span data-stu-id="d7118-164">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="d7118-165">エクスポートされたデータを Gzip 圧縮形式で保存することで、ネットワーク転送を高速化できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-165">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="d7118-166">ただし、ウェアハウスへの圧縮ファイルの読み込みは圧縮されていないファイルの読み込みよりも時間がかかるため、高速ネットワーク転送と高速読み込みの間にはトレードオフがあります。</span><span class="sxs-lookup"><span data-stu-id="d7118-166">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="d7118-167">Gzip 圧縮を使用する場合は、単一の Gzip ファイルを作成しないでください。</span><span class="sxs-lookup"><span data-stu-id="d7118-167">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="d7118-168">代わりに、データを複数の圧縮ファイルに分割します。</span><span class="sxs-lookup"><span data-stu-id="d7118-168">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="d7118-169">フラット ファイルを Blob Storage にコピーする</span><span class="sxs-lookup"><span data-stu-id="d7118-169">Copy flat files into blob storage</span></span>

<span data-ttu-id="d7118-170">[AzCopy](/azure/storage/common/storage-use-azcopy) ユーティリティは、Azure Blob Storage への高パフォーマンスのデータ コピーを実行するように設計されています。</span><span class="sxs-lookup"><span data-stu-id="d7118-170">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="d7118-171">**推奨事項:**</span><span class="sxs-lookup"><span data-stu-id="d7118-171">**Recommendations:**</span></span>

<span data-ttu-id="d7118-172">ソース データの場所に近いリージョンにストレージ アカウントを作成します。</span><span class="sxs-lookup"><span data-stu-id="d7118-172">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="d7118-173">ストレージ アカウントと SQL Data Warehouse インスタンスを同じリージョンにデプロイします。</span><span class="sxs-lookup"><span data-stu-id="d7118-173">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span>

<span data-ttu-id="d7118-174">CPU と I/O の消費が運用ワークロードを妨げる可能性があるため、運用ワークロードを実行するマシンで AzCopy を実行しないでください。</span><span class="sxs-lookup"><span data-stu-id="d7118-174">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span>

<span data-ttu-id="d7118-175">まず、アップロードをテストして、アップロード速度を確認します。</span><span class="sxs-lookup"><span data-stu-id="d7118-175">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="d7118-176">AzCopy で /NC オプションを使用して、コンカレントなコピー操作数を指定できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-176">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="d7118-177">既定値から始め、この設定を試してパフォーマンスを調整します。</span><span class="sxs-lookup"><span data-stu-id="d7118-177">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="d7118-178">低帯域幅の環境では、同時実行操作数が多すぎると、ネットワーク接続に過剰な負荷がかかり、操作を正常に完了できなくなる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-178">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>

<span data-ttu-id="d7118-179">AzCopy では、パブリック インターネット経由でデータをストレージに移動します。</span><span class="sxs-lookup"><span data-stu-id="d7118-179">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="d7118-180">速度が不十分な場合は、[ExpressRoute](/azure/expressroute/) 回線を設定することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-180">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="d7118-181">ExpressRoute は、専用プライベート接続を通してデータを Azure にルーティングするサービスです。</span><span class="sxs-lookup"><span data-stu-id="d7118-181">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="d7118-182">ネットワーク接続が遅すぎる場合は、別の方法として、ディスク上のデータを Azure データセンターに物理的に送付します。</span><span class="sxs-lookup"><span data-stu-id="d7118-182">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="d7118-183">詳細については、「[Azure との間のデータ転送](/azure/architecture/data-guide/scenarios/data-transfer)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-183">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="d7118-184">コピー操作中に、AzCopy によって一時ジャーナル ファイルが作成されます。これにより、(ネットワーク エラーなどが原因で) 操作が中断された場合に、AzCopy で操作を再開できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-184">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="d7118-185">ジャーナル ファイルを格納できる十分なディスク領域があることを確認してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-185">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="d7118-186">/Z オプションを使用して、ジャーナル ファイルの書き込み先を指定できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-186">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="d7118-187">SQL Data Warehouse にデータを読み込む</span><span class="sxs-lookup"><span data-stu-id="d7118-187">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="d7118-188">[PolyBase](/sql/relational-databases/polybase/polybase-guide) を使用して、Blob Storage からデータ ウェアハウスにファイルを読み込みます。</span><span class="sxs-lookup"><span data-stu-id="d7118-188">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="d7118-189">PolyBase は、SQL Data Warehouse の MPP (超並列処理) アーキテクチャを活用するように設計されているので、SQL Data Warehouse にデータを読み込む最も速い方法です。</span><span class="sxs-lookup"><span data-stu-id="d7118-189">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span>

<span data-ttu-id="d7118-190">データの読み込みは次の 2 段階のプロセスです。</span><span class="sxs-lookup"><span data-stu-id="d7118-190">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="d7118-191">データの一連の外部テーブルを作成します。</span><span class="sxs-lookup"><span data-stu-id="d7118-191">Create a set of external tables for the data.</span></span> <span data-ttu-id="d7118-192">外部テーブルとは、ウェアハウスの外部に格納されたデータを参照するテーブル定義です。この場合は、Blob Storage 内のフラット ファイルです。</span><span class="sxs-lookup"><span data-stu-id="d7118-192">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="d7118-193">この手順では、データをウェアハウスに移動しません。</span><span class="sxs-lookup"><span data-stu-id="d7118-193">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="d7118-194">ステージング テーブルを作成し、データをステージング テーブルに読み込みます。</span><span class="sxs-lookup"><span data-stu-id="d7118-194">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="d7118-195">この手順でデータをウェアハウスにコピーします。</span><span class="sxs-lookup"><span data-stu-id="d7118-195">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="d7118-196">**推奨事項:**</span><span class="sxs-lookup"><span data-stu-id="d7118-196">**Recommendations:**</span></span>

<span data-ttu-id="d7118-197">大量のデータ (1 TB 超) があり、並列処理のメリットが得られる分析ワークロードを実行する場合に、SQL Data Warehouse を検討します。</span><span class="sxs-lookup"><span data-stu-id="d7118-197">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="d7118-198">SQL Data Warehouse は、OLTP ワークロードや小規模のデータ セット (250 GB 未満) には適していません。</span><span class="sxs-lookup"><span data-stu-id="d7118-198">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="d7118-199">250 GB 未満のデータ セットについては、Azure SQL Database または SQL Server を検討します。</span><span class="sxs-lookup"><span data-stu-id="d7118-199">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="d7118-200">詳細については、[データ ウェアハウス](../../data-guide/relational-data/data-warehousing.md)に関する記事をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-200">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="d7118-201">インデックスのないヒープ テーブルとしてステージング テーブルを作成します。</span><span class="sxs-lookup"><span data-stu-id="d7118-201">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="d7118-202">運用テーブルを作成するクエリにより、フル テーブル スキャンが実行されることになるため、ステージング テーブルのインデックスを作成する理由はありません。</span><span class="sxs-lookup"><span data-stu-id="d7118-202">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="d7118-203">PolyBase では、ウェアハウスで並列処理を自動的に利用します。</span><span class="sxs-lookup"><span data-stu-id="d7118-203">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="d7118-204">DWU を増やすと、読み込みパフォーマンスがスケーリングされます。</span><span class="sxs-lookup"><span data-stu-id="d7118-204">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="d7118-205">最適なパフォーマンスを得るために、単一の読み込み操作を使用します。</span><span class="sxs-lookup"><span data-stu-id="d7118-205">For best performance, use a single load operation.</span></span> <span data-ttu-id="d7118-206">入力データをチャンクに分割し、複数の同時読み込みを実行すると、パフォーマンス上のメリットは得られません。</span><span class="sxs-lookup"><span data-stu-id="d7118-206">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="d7118-207">PolyBase では Gzip 圧縮ファイルを読み取ることができます。</span><span class="sxs-lookup"><span data-stu-id="d7118-207">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="d7118-208">ただし、ファイルの圧縮解除はシングル スレッド操作であるため、リーダーは圧縮ファイルごとに 1 つしか使用されません。</span><span class="sxs-lookup"><span data-stu-id="d7118-208">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="d7118-209">そのため、単一の大きな圧縮ファイルの読み込みは避けてください。</span><span class="sxs-lookup"><span data-stu-id="d7118-209">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="d7118-210">代わりに、並列処理を活用するために、データを複数の圧縮ファイルに分割します。</span><span class="sxs-lookup"><span data-stu-id="d7118-210">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span>

<span data-ttu-id="d7118-211">次の制限事項に注意してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-211">Be aware of the following limitations:</span></span>

- <span data-ttu-id="d7118-212">PolyBase でサポートされる最大列サイズは、`varchar(8000)`、`nvarchar(4000)`、または `varbinary(8000)` です。</span><span class="sxs-lookup"><span data-stu-id="d7118-212">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="d7118-213">これらの制限を超えるデータがある場合、1 つの方法として、エクスポート時にデータをチャンクに分割し、インポート後にチャンクを再構築します。</span><span class="sxs-lookup"><span data-stu-id="d7118-213">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span>

- <span data-ttu-id="d7118-214">PolyBase では、固定行ターミネータとして \n または改行を使用します。</span><span class="sxs-lookup"><span data-stu-id="d7118-214">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="d7118-215">ソース データに改行文字が出現すると、問題が発生する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-215">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="d7118-216">ソース データ スキーマに、SQL Data Warehouse でサポートされていないデータ型が含まれている場合があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-216">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="d7118-217">これらの制限を回避するには、必要な変換を実行するストアド プロシージャを作成します。</span><span class="sxs-lookup"><span data-stu-id="d7118-217">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="d7118-218">bcp の実行時に、このストアド プロシージャを参照します。</span><span class="sxs-lookup"><span data-stu-id="d7118-218">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="d7118-219">また、[Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) を使用して、SQL Data Warehouse でサポートされていないデータ型を自動的に変換することもできます。</span><span class="sxs-lookup"><span data-stu-id="d7118-219">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="d7118-220">詳細については、次の記事を参照してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-220">For more information, see the following articles:</span></span>

- <span data-ttu-id="d7118-221">[Azure SQL Data Warehouse へのデータ読み込みのベスト プラクティス](/azure/sql-data-warehouse/guidance-for-loading-data)</span><span class="sxs-lookup"><span data-stu-id="d7118-221">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- [<span data-ttu-id="d7118-222">SQL Data Warehouse にスキーマを移行する</span><span class="sxs-lookup"><span data-stu-id="d7118-222">Migrate your schemas to SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)
- [<span data-ttu-id="d7118-223">SQL Data Warehouse でのテーブルのデータ型の定義に関するガイダンス</span><span class="sxs-lookup"><span data-stu-id="d7118-223">Guidance for defining data types for tables in SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)

### <a name="transform-the-data"></a><span data-ttu-id="d7118-224">データの変換</span><span class="sxs-lookup"><span data-stu-id="d7118-224">Transform the data</span></span>

<span data-ttu-id="d7118-225">データを変換し、運用テーブルに移動します。</span><span class="sxs-lookup"><span data-stu-id="d7118-225">Transform the data and move it into production tables.</span></span> <span data-ttu-id="d7118-226">この手順では、ディメンション テーブルとファクト テーブルで構成され、セマンティック モデリングに適したスター スキーマにデータが変換されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-226">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="d7118-227">クラスター化列ストア インデックスを設定して運用テーブルを作成します。これにより、全体として最適なクエリ パフォーマンスが実現されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-227">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="d7118-228">列ストア インデックスは、多数のレコードをスキャンするクエリに最適化されています。</span><span class="sxs-lookup"><span data-stu-id="d7118-228">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="d7118-229">列ストア インデックスは、シングルトンのルックアップ (つまり、単一行の検索) には適していません。</span><span class="sxs-lookup"><span data-stu-id="d7118-229">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="d7118-230">単一ルックアップを頻繁に実行する必要がある場合は、テーブルに非クラスター化インデックスを追加できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-230">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="d7118-231">非クラスター化インデックスを使用すると、単一ルックアップの実行を大幅に高速化できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-231">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="d7118-232">ただし、データ ウェアハウス シナリオでは、通常、単一ルックアップは OLTP ワークロードほど一般的ではありません。</span><span class="sxs-lookup"><span data-stu-id="d7118-232">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="d7118-233">詳細については、「[SQL Data Warehouse でのテーブルのインデックス作成](/azure/sql-data-warehouse/sql-data-warehouse-tables-index)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-233">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="d7118-234">クラスター化列ストア テーブルでは、`varchar(max)`、`nvarchar(max)`、`varbinary(max)` の各データ型はサポートしていません。</span><span class="sxs-lookup"><span data-stu-id="d7118-234">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="d7118-235">その場合、ヒープ インデックスまたはクラスター化インデックスを検討してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-235">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="d7118-236">それらの列を別のテーブルに配置できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-236">You might put those columns into a separate table.</span></span>

<span data-ttu-id="d7118-237">サンプル データベースはそれほど大きくないので、パーティションなしでレプリケート テーブルが作成されました。</span><span class="sxs-lookup"><span data-stu-id="d7118-237">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="d7118-238">運用ワークロードでは、分散テーブルを使用すると、クエリ パフォーマンスが向上する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-238">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="d7118-239">「[Azure SQL Data Warehouse での分散テーブルの設計に関するガイダンス](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-239">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="d7118-240">サンプル スクリプトでは、静的[リソース クラス](/azure/sql-data-warehouse/resource-classes-for-workload-management)を使用してクエリが実行されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-240">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="d7118-241">セマンティック モデルを読み込む</span><span class="sxs-lookup"><span data-stu-id="d7118-241">Load the semantic model</span></span>

<span data-ttu-id="d7118-242">Azure Analysis Services で表形式モデルにデータを読み込みます。</span><span class="sxs-lookup"><span data-stu-id="d7118-242">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="d7118-243">この手順では、SQL Server Data Tools (SSDT) を使用してセマンティック データ モデルを作成します。</span><span class="sxs-lookup"><span data-stu-id="d7118-243">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="d7118-244">モデルは、Power BI Desktop ファイルからインポートして作成することもできます。</span><span class="sxs-lookup"><span data-stu-id="d7118-244">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="d7118-245">SQL Data Warehouse では外部キーをサポートしていないため、テーブル間の結合を可能にするために、セマンティック モデルにリレーションシップを追加する必要があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-245">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="d7118-246">Power BI を使用してデータを視覚化する</span><span class="sxs-lookup"><span data-stu-id="d7118-246">Use Power BI to visualize the data</span></span>

<span data-ttu-id="d7118-247">Power BI では、Azure Analysis Services に接続するための 2 つのオプションをサポートしています。</span><span class="sxs-lookup"><span data-stu-id="d7118-247">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="d7118-248">インポート。</span><span class="sxs-lookup"><span data-stu-id="d7118-248">Import.</span></span> <span data-ttu-id="d7118-249">データは Power BI モデルにインポートされます。</span><span class="sxs-lookup"><span data-stu-id="d7118-249">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="d7118-250">ライブ接続。</span><span class="sxs-lookup"><span data-stu-id="d7118-250">Live Connection.</span></span> <span data-ttu-id="d7118-251">データは Analysis Services から直接取得されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-251">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="d7118-252">Power BI モデルにデータをコピーする必要がないため、ライブ接続をお勧めします。</span><span class="sxs-lookup"><span data-stu-id="d7118-252">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="d7118-253">また、DirectQuery を使用すると、結果を最新のソース データと常に一致させることができます。</span><span class="sxs-lookup"><span data-stu-id="d7118-253">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="d7118-254">詳細については、「[Power BI を使用した接続](/azure/analysis-services/analysis-services-connect-pbi)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-254">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="d7118-255">**推奨事項:**</span><span class="sxs-lookup"><span data-stu-id="d7118-255">**Recommendations:**</span></span>

<span data-ttu-id="d7118-256">BI ダッシュボードのクエリをデータ ウェアハウスに対して直接実行しないようにしてください。</span><span class="sxs-lookup"><span data-stu-id="d7118-256">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="d7118-257">BI ダッシュボードでは、応答時間が非常に短いことが求められます。ウェアハウスに対してクエリを直接実行すると、この要件を満たすことができない可能性があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-257">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="d7118-258">また、ダッシュボードの更新は同時クエリの数にカウントされるので、パフォーマンスに影響を及ぼす可能性があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-258">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span>

<span data-ttu-id="d7118-259">Azure Analysis Services は、BI ダッシュボードのクエリ要件に対応するように設計されているため、Power BI から Analysis Services に対するクエリを実行することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="d7118-259">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="d7118-260">スケーラビリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="d7118-260">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="d7118-261">SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="d7118-261">SQL Data Warehouse</span></span>

<span data-ttu-id="d7118-262">SQL Data Warehouse では、コンピューティング リソースをオンデマンドでスケールアウトできます。</span><span class="sxs-lookup"><span data-stu-id="d7118-262">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="d7118-263">クエリ エンジンは、コンピューティング ノードの数に基づいてクエリを並列処理に最適化し、必要に応じてノード間でデータを移動します。</span><span class="sxs-lookup"><span data-stu-id="d7118-263">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="d7118-264">詳細については、「[Azure SQL Data Warehouse でのコンピューティングの管理](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-264">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="d7118-265">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="d7118-265">Analysis Services</span></span>

<span data-ttu-id="d7118-266">Azure Analysis Services の Standard レベルでは、パーティション分割と DirectQuery をサポートしているため、運用ワークロードには Standard レベルをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="d7118-266">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="d7118-267">レベル内では、インスタンスのサイズによってメモリと処理能力が決まります。</span><span class="sxs-lookup"><span data-stu-id="d7118-267">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="d7118-268">処理能力は、クエリ処理ユニット (QPU) で測定されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-268">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="d7118-269">QPU 使用量を監視して適切なサイズを選択します。</span><span class="sxs-lookup"><span data-stu-id="d7118-269">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="d7118-270">詳細については、「[サーバー メトリックの監視](/azure/analysis-services/analysis-services-monitor)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-270">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="d7118-271">高負荷時には、クエリのコンカレンシーによってクエリ パフォーマンスが低下する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-271">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="d7118-272">より多くのクエリを同時に実行できるように、クエリを処理するレプリカのプールを作成して Analysis Services をスケールアウトできます。</span><span class="sxs-lookup"><span data-stu-id="d7118-272">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="d7118-273">データ モデルの処理は、常にプライマリ サーバーで行われます。</span><span class="sxs-lookup"><span data-stu-id="d7118-273">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="d7118-274">既定では、クエリもプライマリ サーバーで処理されます。</span><span class="sxs-lookup"><span data-stu-id="d7118-274">By default, the primary server also handles queries.</span></span> <span data-ttu-id="d7118-275">必要に応じて、クエリ プールですべてのクエリが処理されるように、処理を排他的に実行するプライマリ サーバーを指定することもできます。</span><span class="sxs-lookup"><span data-stu-id="d7118-275">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="d7118-276">高い処理要件がある場合は、クエリ プールから処理を切り離す必要があります。</span><span class="sxs-lookup"><span data-stu-id="d7118-276">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="d7118-277">クエリ負荷が高く、処理が比較的軽い場合は、プライマリ サーバーをクエリ プールに含めることができます。</span><span class="sxs-lookup"><span data-stu-id="d7118-277">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="d7118-278">詳細については、「[Azure Analysis Services のスケールアウト](/azure/analysis-services/analysis-services-scale-out)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-278">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span>

<span data-ttu-id="d7118-279">不要な処理の量を減らすために、パーティションを使用して表形式モデルを論理部分に分割することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-279">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="d7118-280">各パーティションは個別に処理できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-280">Each partition can be processed separately.</span></span> <span data-ttu-id="d7118-281">詳細については、「[パーティション](/sql/analysis-services/tabular-models/partitions-ssas-tabular)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-281">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="d7118-282">セキュリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="d7118-282">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="d7118-283">Analysis Services クライアントの IP ホワイトリスト登録</span><span class="sxs-lookup"><span data-stu-id="d7118-283">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="d7118-284">Analysis Services のファイアウォール機能を使用して、クライアントの IP アドレスをホワイトリストに登録することを検討します。</span><span class="sxs-lookup"><span data-stu-id="d7118-284">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="d7118-285">ファイアウォールを有効にすると、ファイアウォール規則で指定された接続以外のすべてのクライアント接続がブロックされます。</span><span class="sxs-lookup"><span data-stu-id="d7118-285">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="d7118-286">既定の規則では Power BI サービスがホワイトリストに登録されますが、必要に応じてこの規則を無効にすることができます。</span><span class="sxs-lookup"><span data-stu-id="d7118-286">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="d7118-287">詳細については、「[Hardening Azure Analysis Services with the new firewall capability (新しいファイアウォール機能による Azure Analysis Services の強化)](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-287">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="d7118-288">承認</span><span class="sxs-lookup"><span data-stu-id="d7118-288">Authorization</span></span>

<span data-ttu-id="d7118-289">Azure Analysis Services では、Azure Active Directory (Azure AD) を使用して Analysis Services サーバーに接続するユーザーを認証します。</span><span class="sxs-lookup"><span data-stu-id="d7118-289">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="d7118-290">ロールを作成し、Azure AD ユーザーまたはグループをそれらのロールに割り当てることで、特定のユーザーが表示できるデータを制限できます。</span><span class="sxs-lookup"><span data-stu-id="d7118-290">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="d7118-291">各ロールでは次のことが可能です。</span><span class="sxs-lookup"><span data-stu-id="d7118-291">For each role, you can:</span></span>

- <span data-ttu-id="d7118-292">テーブルまたは個々の列を保護する。</span><span class="sxs-lookup"><span data-stu-id="d7118-292">Protect tables or individual columns.</span></span>
- <span data-ttu-id="d7118-293">フィルター式に基づいて個々の行を保護する。</span><span class="sxs-lookup"><span data-stu-id="d7118-293">Protect individual rows based on filter expressions.</span></span>

<span data-ttu-id="d7118-294">詳細については、「[データベース ロールとユーザーの管理](/azure/analysis-services/analysis-services-database-users)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="d7118-294">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="d7118-295">ソリューションのデプロイ方法</span><span class="sxs-lookup"><span data-stu-id="d7118-295">Deploy the solution</span></span>

<span data-ttu-id="d7118-296">リファレンス実装をデプロイおよび実行するには、[GitHub readme][github-folder] の手順に従ってください。</span><span class="sxs-lookup"><span data-stu-id="d7118-296">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github-folder].</span></span> <span data-ttu-id="d7118-297">以下がデプロイされます。</span><span class="sxs-lookup"><span data-stu-id="d7118-297">It deploys the following:</span></span>

- <span data-ttu-id="d7118-298">オンプレミスのデータベース サーバーをシミュレートする Windows VM。</span><span class="sxs-lookup"><span data-stu-id="d7118-298">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="d7118-299">これには、SQL Server 2017 と関連ツール、および Power BI Desktop が含まれています。</span><span class="sxs-lookup"><span data-stu-id="d7118-299">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
- <span data-ttu-id="d7118-300">SQL Server データベースからエクスポートされたデータを保持する Blob Storage を提供する Azure ストレージ アカウント。</span><span class="sxs-lookup"><span data-stu-id="d7118-300">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
- <span data-ttu-id="d7118-301">Azure SQL Data Warehouse インスタンス。</span><span class="sxs-lookup"><span data-stu-id="d7118-301">An Azure SQL Data Warehouse instance.</span></span>
- <span data-ttu-id="d7118-302">Azure Analysis Services インスタンス。</span><span class="sxs-lookup"><span data-stu-id="d7118-302">An Azure Analysis Services instance.</span></span>

## <a name="next-steps"></a><span data-ttu-id="d7118-303">次の手順</span><span class="sxs-lookup"><span data-stu-id="d7118-303">Next steps</span></span>

- <span data-ttu-id="d7118-304">Azure Data Factory を使用して ELT パイプラインを自動化します。</span><span class="sxs-lookup"><span data-stu-id="d7118-304">Use Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="d7118-305">「[SQL Data Warehouse と Azure Data Factory を使用したエンタープライズ BI の自動化][adf-ra]」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="d7118-305">See [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="related-resources"></a><span data-ttu-id="d7118-306">関連リソース</span><span class="sxs-lookup"><span data-stu-id="d7118-306">Related resources</span></span>

<span data-ttu-id="d7118-307">同じテクノロジの一部を使用する具体的なソリューションを示す次の [Azure のサンプル シナリオ](/azure/architecture/example-scenario)をレビューできます。</span><span class="sxs-lookup"><span data-stu-id="d7118-307">You may want to review the following [Azure example scenarios](/azure/architecture/example-scenario) that demonstrate specific solutions using some of the same technologies:</span></span>

- [<span data-ttu-id="d7118-308">販売およびマーケティング向けのデータ ウェアハウスと分析</span><span class="sxs-lookup"><span data-stu-id="d7118-308">Data warehousing and analytics for sales and marketing</span></span>](/azure/architecture/example-scenario/data/data-warehouse)
- [<span data-ttu-id="d7118-309">既存のオンプレミス SSIS と Azure Data Factory を使用したハイブリッド ETL</span><span class="sxs-lookup"><span data-stu-id="d7118-309">Hybrid ETL with existing on-premises SSIS and Azure Data Factory</span></span>](/azure/architecture/example-scenario/data/hybrid-etl-with-adf)

<!-- links -->

[adf-ra]: ./enterprise-bi-adf.md
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database
