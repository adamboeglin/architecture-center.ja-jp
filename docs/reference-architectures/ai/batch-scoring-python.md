---
title: Azure での Python モデルのバッチ スコアリング
description: Azure Machine Learning service を使用して、スケジュールに従って複数のモデルのバッチ スコアリングを並列で実行するスケーラブルなソリューションをビルドします。
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: b7607984bcf2c4bd046421aeb6e9d52dd8e7c18e
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887745"
---
# <a name="batch-scoring-of-python-machine-learning-models-on-azure"></a><span data-ttu-id="35df0-103">Azure での Python 機械学習モデルのバッチ スコアリング</span><span class="sxs-lookup"><span data-stu-id="35df0-103">Batch scoring of Python machine learning models on Azure</span></span>

<span data-ttu-id="35df0-104">この参照アーキテクチャでは、Azure Machine Learning service を使用して、スケジュールに従って多数のモデルのバッチ スコアリングを並列で実行するスケーラブルなソリューションをビルドする方法を示します。</span><span class="sxs-lookup"><span data-stu-id="35df0-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="35df0-105">このソリューションはテンプレートとして使用でき、さまざまな問題に対応するように汎用化できます。</span><span class="sxs-lookup"><span data-stu-id="35df0-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="35df0-106">このアーキテクチャのリファレンス実装は、[GitHub][github] で入手できます。</span><span class="sxs-lookup"><span data-stu-id="35df0-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Azure での Python モデルのバッチ スコアリング](./_images/batch-scoring-python.png)

<span data-ttu-id="35df0-108">**シナリオ**: このソリューションでは、各デバイスがセンサーの測定値を継続的に送信する IoT 設定内の多数のデバイスの運用を監視します。</span><span class="sxs-lookup"><span data-stu-id="35df0-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="35df0-109">各デバイスには、定義済みの期間にわたって集計される一連の測定値が異常に該当するか否かを予測するために使用する必要がある、トレーニング済みの異常検出モデルが関連付けられていることを前提としています。</span><span class="sxs-lookup"><span data-stu-id="35df0-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="35df0-110">現実のシナリオでは、これは、トレーニングやリアルタイム スコアリングで使用する前に、フィルター処理や集計を行う必要があるセンサーの測定値のストリームが考えられます。</span><span class="sxs-lookup"><span data-stu-id="35df0-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="35df0-111">単純化するために、このソリューションでは、スコアリング ジョブを実行するときに同じデータ ファイルを使用します。</span><span class="sxs-lookup"><span data-stu-id="35df0-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="35df0-112">この参照アーキテクチャは、スケジュールに従ってトリガーされるワークロード用に設計されています。</span><span class="sxs-lookup"><span data-stu-id="35df0-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="35df0-113">処理には次の手順が含まれます。</span><span class="sxs-lookup"><span data-stu-id="35df0-113">Processing involves the following steps:</span></span>
1.  <span data-ttu-id="35df0-114">インジェストのセンサー読み取り値を、Azure Event Hubs に送信します。</span><span class="sxs-lookup"><span data-stu-id="35df0-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2.  <span data-ttu-id="35df0-115">ストリーム処理を実行し、生データを保存します。</span><span class="sxs-lookup"><span data-stu-id="35df0-115">Perform stream processing and store the raw data.</span></span>
3.  <span data-ttu-id="35df0-116">処理を開始する準備ができている Machine Learning クラスターにデータを送信します。</span><span class="sxs-lookup"><span data-stu-id="35df0-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="35df0-117">クラスター内の各ノードで、特定のセンサーに対するスコアリング ジョブを実行します。</span><span class="sxs-lookup"><span data-stu-id="35df0-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4.  <span data-ttu-id="35df0-118">Machine Learning Python スクリプトを使用して並列でスコアリング ジョブを実行するスコアリング パイプラインを実行します。</span><span class="sxs-lookup"><span data-stu-id="35df0-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="35df0-119">パイプラインが作成および公開され、事前定義された間隔で実行されるようにスケジュールされます。</span><span class="sxs-lookup"><span data-stu-id="35df0-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5.  <span data-ttu-id="35df0-120">予測を生成し、後で使用できるように Blob Storage に保存します。</span><span class="sxs-lookup"><span data-stu-id="35df0-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="35df0-121">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="35df0-121">Architecture</span></span>

<span data-ttu-id="35df0-122">このアーキテクチャは、次のコンポーネントで構成されます。</span><span class="sxs-lookup"><span data-stu-id="35df0-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="35df0-123">[Azure Event Hubs][event-hubs]。</span><span class="sxs-lookup"><span data-stu-id="35df0-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="35df0-124">このメッセージ インジェスト サービスでは、1 秒あたり数百万件のイベント メッセージを取り込むことができます。</span><span class="sxs-lookup"><span data-stu-id="35df0-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="35df0-125">このアーキテクチャでは、センサーがこのイベント ハブにデータ ストリームを送信します。</span><span class="sxs-lookup"><span data-stu-id="35df0-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="35df0-126">[Azure Stream Analytics][stream-analytics]。</span><span class="sxs-lookup"><span data-stu-id="35df0-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="35df0-127">イベント処理エンジンです。</span><span class="sxs-lookup"><span data-stu-id="35df0-127">An event-processing engine.</span></span> <span data-ttu-id="35df0-128">Stream Analytics ジョブがイベント ハブからデータ ストリームを読み取り、ストリーム処理を実行します。</span><span class="sxs-lookup"><span data-stu-id="35df0-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="35df0-129">[Azure SQL Database][sql-database]。</span><span class="sxs-lookup"><span data-stu-id="35df0-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="35df0-130">センサー読み取り値のデータは、SQL Database に読み込まれます。</span><span class="sxs-lookup"><span data-stu-id="35df0-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="35df0-131">SQL は、処理済みのストリーミング データ (表形式および構造化) を格納するための一般的な方法ですが、他のデータ ストアを使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="35df0-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="35df0-132">[Azure Machine Learning service][amls]。</span><span class="sxs-lookup"><span data-stu-id="35df0-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="35df0-133">Machine Learning は、大規模な機械学習モデルをトレーニング、スコアリング、デプロイ、および管理するためのクラウド サービスです。</span><span class="sxs-lookup"><span data-stu-id="35df0-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="35df0-134">バッチ スコアリングのコンテキストでは、Machine Learning は自動スケーリング オプションを使用してオンデマンドで仮想マシンのクラスターを作成し、クラスター内の各ノードで特定のセンサーに対するスコアリング ジョブを実行します。</span><span class="sxs-lookup"><span data-stu-id="35df0-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="35df0-135">スコアリング ジョブは、Machine Learning によってキューに登録されて管理される、Python スクリプトのステップとして、並列で実行されます。</span><span class="sxs-lookup"><span data-stu-id="35df0-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="35df0-136">これらのステップは、作成および公開され、事前定義された間隔で実行されるようにスケジュールされた Machine Learning パイプラインの一部です。</span><span class="sxs-lookup"><span data-stu-id="35df0-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="35df0-137">[Azure Blob Storage][storage]。</span><span class="sxs-lookup"><span data-stu-id="35df0-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="35df0-138">BLOB コンテナーを使用して、事前トレーニング済みモデル、データ、および出力予測が格納されます。</span><span class="sxs-lookup"><span data-stu-id="35df0-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="35df0-139">モデルは、Blob Storage の [01_create_resources.ipynb][create-resources] ノートブックにアップロードされます。</span><span class="sxs-lookup"><span data-stu-id="35df0-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="35df0-140">これらの [1 クラス SVM][one-class-svm] モデルが、異なるデバイスの異なるセンサーの値を表すデータでトレーニングされます。</span><span class="sxs-lookup"><span data-stu-id="35df0-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="35df0-141">このソリューションでは、固定された期間にわたってデータ値が集計されることを前提としています。</span><span class="sxs-lookup"><span data-stu-id="35df0-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="35df0-142">[Azure Container Registry][acr]。</span><span class="sxs-lookup"><span data-stu-id="35df0-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="35df0-143">スコアリング Python [スクリプト][pyscript]は、クラスターの各ノードに作成される Docker コンテナーで実行され、関連するセンサーのデータを読み取り、予測を生成して Blob Storage に格納します。</span><span class="sxs-lookup"><span data-stu-id="35df0-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="35df0-144">パフォーマンスに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="35df0-144">Performance considerations</span></span>

<span data-ttu-id="35df0-145">標準的な Python モデルでは、CPU で十分にワークロードを処理できることが一般に認められています。</span><span class="sxs-lookup"><span data-stu-id="35df0-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="35df0-146">このアーキテクチャでは、CPU を使用します。</span><span class="sxs-lookup"><span data-stu-id="35df0-146">This architecture uses CPUs.</span></span> <span data-ttu-id="35df0-147">ただし、[ディープ ラーニング ワークロード][deep]では、通常は、CPU より GPU の方が優れています。多くの場合、同等のパフォーマンスを得るためには巨大な CPU クラスターが必要です。</span><span class="sxs-lookup"><span data-stu-id="35df0-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount &mdash; a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="35df0-148">VM とコアの間の並列化</span><span class="sxs-lookup"><span data-stu-id="35df0-148">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="35df0-149">多数のモデルのスコアリング プロセスをバッチ モードで実行する場合は、VM 間でジョブを並列処理する必要があります。</span><span class="sxs-lookup"><span data-stu-id="35df0-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="35df0-150">2 つの方法が可能であり、</span><span class="sxs-lookup"><span data-stu-id="35df0-150">Two approaches are possible:</span></span>

* <span data-ttu-id="35df0-151">低コストの VM を使用して大規模なクラスターを作成する。</span><span class="sxs-lookup"><span data-stu-id="35df0-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="35df0-152">高パフォーマンスの VM を使用する小規模なクラスターを作成し、それぞれで複数のコアを使用できるようにする。</span><span class="sxs-lookup"><span data-stu-id="35df0-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="35df0-153">一般に、標準的な Python モデルのスコアリングはディープ ラーニング モデルのスコアリングほど負荷が高くないため、小規模のクラスターでキューに置かれた多数のモデルを効率的に処理できます。</span><span class="sxs-lookup"><span data-stu-id="35df0-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="35df0-154">データセットのサイズが大きくなったときに、クラスター ノードの数を増やすことができます。</span><span class="sxs-lookup"><span data-stu-id="35df0-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="35df0-155">このシナリオでは便宜上、単一の Machine Learning パイプライン ステップ内で 1 つのスコアリング タスクを送信します。</span><span class="sxs-lookup"><span data-stu-id="35df0-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="35df0-156">ただし、同じパイプライン ステップ内で複数のデータ チャンクをスコアリングすることで、効率を上げることができます。</span><span class="sxs-lookup"><span data-stu-id="35df0-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="35df0-157">この場合は、単一ステップの実行中に、複数のデータセットを読み取り、それらに対してスコアリング スクリプトを実行するカスタム コードを記述します。</span><span class="sxs-lookup"><span data-stu-id="35df0-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="35df0-158">管理の考慮事項</span><span class="sxs-lookup"><span data-stu-id="35df0-158">Management considerations</span></span>

- <span data-ttu-id="35df0-159">**ジョブの監視**。</span><span class="sxs-lookup"><span data-stu-id="35df0-159">**Monitor jobs**.</span></span> <span data-ttu-id="35df0-160">実行中のジョブの進行状況を監視することは重要ですが、アクティブ ノードのクラスターを監視することは困難である可能性があります。</span><span class="sxs-lookup"><span data-stu-id="35df0-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="35df0-161">クラスター内のノードの状態を調べるには、[Azure portal][portal] を使用して、[機械学習ワークスペース][ml-workspace]を管理します。</span><span class="sxs-lookup"><span data-stu-id="35df0-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="35df0-162">ノードが非アクティブになった場合、またはジョブが失敗した場合は、エラー ログが Blob Storage に保存され、[パイプライン] セクションからアクセスすることもできます。</span><span class="sxs-lookup"><span data-stu-id="35df0-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="35df0-163">監視を強化するには、ログを [Application Insights][app-insights] に接続するか、クラスターとそのジョブの状態をポーリングする別のプロセスを実行します。</span><span class="sxs-lookup"><span data-stu-id="35df0-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
-   <span data-ttu-id="35df0-164">**ログの記録**。</span><span class="sxs-lookup"><span data-stu-id="35df0-164">**Logging**.</span></span> <span data-ttu-id="35df0-165">Machine Learning service では、関連付けられている Azure ストレージ アカウントにすべての stdout/stderr が記録されます。</span><span class="sxs-lookup"><span data-stu-id="35df0-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="35df0-166">ログ ファイルを簡単に表示するには、[Azure Storage Explorer][explorer] などのストレージ ナビゲーション ツールを使用します。</span><span class="sxs-lookup"><span data-stu-id="35df0-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="35df0-167">コストに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="35df0-167">Cost considerations</span></span>

<span data-ttu-id="35df0-168">この参照アーキテクチャで使用される最も高価なコンポーネントは、コンピューティング リソースです。</span><span class="sxs-lookup"><span data-stu-id="35df0-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="35df0-169">コンピューティング クラスターのサイズは、キュー内のジョブに応じて、スケールアップおよびスケールダウンされます。</span><span class="sxs-lookup"><span data-stu-id="35df0-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="35df0-170">自動スケーリングは、Python SDK を介してコンピューティングのプロビジョニング構成を変更することで、プログラムから有効にします。</span><span class="sxs-lookup"><span data-stu-id="35df0-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="35df0-171">または、[Azure CLI][cli] を使用して、クラスターの自動スケーリング パラメーターを設定します。</span><span class="sxs-lookup"><span data-stu-id="35df0-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="35df0-172">即時処理を必要としない作業の場合は、既定の状態 (最小) が 0 個のノードのクラスターになるように、自動スケーリング式を構成します。</span><span class="sxs-lookup"><span data-stu-id="35df0-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="35df0-173">この構成では、クラスターは 0 個のノードで開始し、キュー内でジョブが検出されたときのみスケールアップします。</span><span class="sxs-lookup"><span data-stu-id="35df0-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="35df0-174">バッチ スコアリング プロセスが 1 日に数回以下しか発生しない場合は、この設定により大幅なコスト削減を実現できます。</span><span class="sxs-lookup"><span data-stu-id="35df0-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="35df0-175">非常に短い間隔で発生するバッチ ジョブでは、自動スケーリングは適切ではない場合があります。</span><span class="sxs-lookup"><span data-stu-id="35df0-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="35df0-176">クラスターの起動と停止に要する時間にもコストがかかるので、前のジョブの終了後ほんの数分でバッチ ワークロードが開始する場合は、ジョブ間もクラスターを実行したままにする方がコスト効率がよくなる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="35df0-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="35df0-177">これは、スコアリング プロセスが高い頻度で (たとえば 1 時間ごとに) 実行されるようにスケジュールされるか、低い頻度で (たとえば 1 か月に 1 回) 実行されるようにスケジュールされるかによって決まります。</span><span class="sxs-lookup"><span data-stu-id="35df0-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>


## <a name="deployment"></a><span data-ttu-id="35df0-178">Deployment</span><span class="sxs-lookup"><span data-stu-id="35df0-178">Deployment</span></span>

<span data-ttu-id="35df0-179">この参照アーキテクチャを展開するには、[GitHub リポジトリ][github]で説明されている手順に従ってください。</span><span class="sxs-lookup"><span data-stu-id="35df0-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: /cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: /azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: /azure/sql-database/
[app-insights]: /azure/application-insights/app-insights-overview
