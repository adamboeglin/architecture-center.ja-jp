---
title: マイクロサービスでのインジェストとワークフロー
description: マイクロサービスでのインジェストとワークフロー
author: MikeWasson
ms.date: 10/23/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: microservices
ms.openlocfilehash: 75aef5aec7f4663abff45ebdba5dbea245d3ac17
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/20/2019
ms.locfileid: "58248457"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="70960-103">マイクロサービスの設計:インジェストとワークフロー</span><span class="sxs-lookup"><span data-stu-id="70960-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="70960-104">多くの場合、マイクロサービスには、1 つのトランザクションの複数のサービスにまたがるワークフローがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="70960-105">ワークフローは信頼性が高くなくてはなりません。トランザクションが失われたり、部分的に完了した状態のままになったりしてはなりません。</span><span class="sxs-lookup"><span data-stu-id="70960-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="70960-106">また、受信要求のインジェスト速度を制御することも重要です。</span><span class="sxs-lookup"><span data-stu-id="70960-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="70960-107">多くの小さなサービスが互いに通信している状況では、受信要求の急増がサービス間通信に大きな負荷をかけることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span>

![インジェスト ワークフローの図](./images/ingestion-workflow.png)

> [!NOTE]
> <span data-ttu-id="70960-109">この記事は、[ドローン配送アプリケーション](./design/index.md)というマイクロサービスの参照実装に基づいています。</span><span class="sxs-lookup"><span data-stu-id="70960-109">This article is based on a microservices reference implementation called the [Drone Delivery application](./design/index.md).</span></span>

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="70960-110">ドローン配信ワークフロー</span><span class="sxs-lookup"><span data-stu-id="70960-110">The drone delivery workflow</span></span>

<span data-ttu-id="70960-111">ドローン配信アプリケーションでは、配信をスケジュールするために以下の操作を実行する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-111">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="70960-112">お客様のアカウントの状態を確認します (アカウント サービス)。</span><span class="sxs-lookup"><span data-stu-id="70960-112">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="70960-113">新しいパッケージ エンティティを作成します (パッケージ サービス)。</span><span class="sxs-lookup"><span data-stu-id="70960-113">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="70960-114">ピックアップと配信の場所に基づいて、この配信にサードパーティの転送が必要かどうかを確認します (サードパーティ転送サービス)。</span><span class="sxs-lookup"><span data-stu-id="70960-114">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="70960-115">ドローンにピックアップをスケジュールします (ドローン サービス)。</span><span class="sxs-lookup"><span data-stu-id="70960-115">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="70960-116">新しい配信エンティティを作成します (配信サービス)。</span><span class="sxs-lookup"><span data-stu-id="70960-116">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="70960-117">これはアプリケーション全体の中核であるため、エンドツーエンド プロセスには高いパフォーマンスと信頼性が必要です。</span><span class="sxs-lookup"><span data-stu-id="70960-117">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="70960-118">いくつかの特定の課題に対処する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-118">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="70960-119">**負荷平準化**。</span><span class="sxs-lookup"><span data-stu-id="70960-119">**Load leveling**.</span></span> <span data-ttu-id="70960-120">クライアント要求が多すぎると、システムはサービス間ネットワーク トラフィックによって過負荷になることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-120">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="70960-121">ストレージやリモート サービスなどのバックエンドの依存関係も圧迫されることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-121">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="70960-122">これらを呼び出すサービスを調整し、システムに背圧を作成することで対応できます。</span><span class="sxs-lookup"><span data-stu-id="70960-122">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="70960-123">そのため、システムに送信される要求をバッファーやキューに入れて処理することで、その負荷を平準化することが重要です。</span><span class="sxs-lookup"><span data-stu-id="70960-123">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span>

- <span data-ttu-id="70960-124">**保証された配信**。</span><span class="sxs-lookup"><span data-stu-id="70960-124">**Guaranteed delivery**.</span></span> <span data-ttu-id="70960-125">クライアント要求のドロップを避けるには、インジェスト コンポーネントが少なくとも 1 回のメッセージ配信を保証する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-125">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span>

- <span data-ttu-id="70960-126">**エラー処理**。</span><span class="sxs-lookup"><span data-stu-id="70960-126">**Error handling**.</span></span> <span data-ttu-id="70960-127">いずれかのサービスがエラー コードを返すか、一時的ではないエラーが発生する場合は、配信をスケジュールできません。</span><span class="sxs-lookup"><span data-stu-id="70960-127">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="70960-128">エラー コードは、予期されるエラー状態 (たとえば、お客様のアカウントが一時停止されている) または予期しないサーバー エラー (HTTP 5xx) を示す可能性があります。</span><span class="sxs-lookup"><span data-stu-id="70960-128">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="70960-129">サービスも利用不可になり、ネットワーク呼び出しがタイムアウトになる原因となることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-129">A service might also be unavailable, causing the network call to time out.</span></span>

<span data-ttu-id="70960-130">まず、式のインジェスト側 (システムが高スループットで受信ユーザー要求を取り込む方法) を確認します。</span><span class="sxs-lookup"><span data-stu-id="70960-130">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="70960-131">次に、ドローン配信アプリケーションで信頼できるワークフローを実装する方法を検討します。</span><span class="sxs-lookup"><span data-stu-id="70960-131">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="70960-132">インジェスト サブシステムの設計がワークフロー バックエンドに影響することがわかります。</span><span class="sxs-lookup"><span data-stu-id="70960-132">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span>

## <a name="ingestion"></a><span data-ttu-id="70960-133">データの取り込み</span><span class="sxs-lookup"><span data-stu-id="70960-133">Ingestion</span></span>

<span data-ttu-id="70960-134">ビジネス要件に基づいて、開発チームは、インジェストについて次の非機能的要件を識別しました。</span><span class="sxs-lookup"><span data-stu-id="70960-134">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="70960-135">10 K 要求数/秒の持続スループット。</span><span class="sxs-lookup"><span data-stu-id="70960-135">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="70960-136">クライアント要求のドロップやタイムアウトなしで最大 50 K/秒の急増に対応できること。</span><span class="sxs-lookup"><span data-stu-id="70960-136">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="70960-137">99 パーセンタイルで 500 ミリ秒未満の待機時間。</span><span class="sxs-lookup"><span data-stu-id="70960-137">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="70960-138">トラフィックの不定期な急増の処理の要件は、設計上の課題を提示します。</span><span class="sxs-lookup"><span data-stu-id="70960-138">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="70960-139">理論上は、システムをスケールアウトして、予想される最大トラフィックを処理できます。</span><span class="sxs-lookup"><span data-stu-id="70960-139">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="70960-140">しかし、多くのリソースのプロビジョニングはとても非効率的です。</span><span class="sxs-lookup"><span data-stu-id="70960-140">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="70960-141">ほとんどの期間、アプリケーションはそれほど大きな容量を必要としないため、コアがアイドル状態となり、費用をかけても価値は付加されません。</span><span class="sxs-lookup"><span data-stu-id="70960-141">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="70960-142">より適切な手法は、受信要求をバッファーに入れて、バッファーで負荷を平準化することです。</span><span class="sxs-lookup"><span data-stu-id="70960-142">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="70960-143">この設計では、インジェスト サービスは短期間に最大のインジェスト速度を処理できる必要がありますが、バックエンド サービスが処理する必要があるのは最大の持続的負荷だけです。</span><span class="sxs-lookup"><span data-stu-id="70960-143">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="70960-144">フロント エンドでバッファー処理すると、バックエンド サービスはトラフィックの急増を処理する必要がなくなります。</span><span class="sxs-lookup"><span data-stu-id="70960-144">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="70960-145">ドローン配信アプリケーションに必要なスケールでは、[Azure Event Hubs](/azure/event-hubs/) が負荷平準化に適しています。</span><span class="sxs-lookup"><span data-stu-id="70960-145">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="70960-146">Event Hubs は、低待機時間と高スループットを提供し、大量のインジェストにおけるコスト効果の高いソリューションとなります。</span><span class="sxs-lookup"><span data-stu-id="70960-146">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span>

<span data-ttu-id="70960-147">テストでは、32 パーティションと 100 スループット ユニットの Standard レベルのイベント ハブを使いました。</span><span class="sxs-lookup"><span data-stu-id="70960-147">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="70960-148">約 90 ミリ秒の待機時間で約 32 K イベント/秒のインジェストが見られました。</span><span class="sxs-lookup"><span data-stu-id="70960-148">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="70960-149">現時点では、既定の上限は 20 スループット ユニットですが、Azure のお客様は、サポート リクエストを申請することによって追加スループット ユニットを要求できます。</span><span class="sxs-lookup"><span data-stu-id="70960-149">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="70960-150">詳しくは、「[Event Hubs のクォータ](/azure/event-hubs/event-hubs-quotas)」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="70960-150">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="70960-151">すべてのパフォーマンス メトリックと同様に、メッセージ ペイロード サイズなどの多くの要因がパフォーマンスに影響する可能性があるため、これらの数値をベンチマークとして解釈しないでください。</span><span class="sxs-lookup"><span data-stu-id="70960-151">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="70960-152">より高いスループットが必要な場合、インジェスト サービスは複数のイベント ハブ間でシャード化することができます。</span><span class="sxs-lookup"><span data-stu-id="70960-152">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="70960-153">さらに高いスループット レートを実現するために、[Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) は 1 秒あたり 200 万を超えるイベントを受信できるシングル テナント デプロイを提供します。</span><span class="sxs-lookup"><span data-stu-id="70960-153">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="70960-154">Event Hubs が高スループットなどを実現する方法はクライアントが Event Hubs からのメッセージを使用する方法に影響するため、これを理解することが重要です。</span><span class="sxs-lookup"><span data-stu-id="70960-154">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="70960-155">Event Hubs は "*キュー*" を実装しません。</span><span class="sxs-lookup"><span data-stu-id="70960-155">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="70960-156">代わりに、"*イベント ストリーム*" を実装します。</span><span class="sxs-lookup"><span data-stu-id="70960-156">Rather, it implements an *event stream*.</span></span>

<span data-ttu-id="70960-157">キューでは、個々のコンシューマーがキューからメッセージを削除することができ、次のコンシューマーにはそのメッセージは見えません。</span><span class="sxs-lookup"><span data-stu-id="70960-157">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="70960-158">そのため、キューを使うと、[競合コンシューマー パターン](../patterns/competing-consumers.md)を使ってメッセージを並列に処理し、スケーラビリティを向上させることができます。</span><span class="sxs-lookup"><span data-stu-id="70960-158">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="70960-159">回復性を高めるために、コンシューマーはメッセージをロックし、メッセージの処理が終わったときにロックを解放します。</span><span class="sxs-lookup"><span data-stu-id="70960-159">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="70960-160">コンシューマーが失敗した場合 (たとえば、実行されているノードがクラッシュした場合)、ロックはタイムアウトになり、メッセージはキューに戻ります。</span><span class="sxs-lookup"><span data-stu-id="70960-160">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span>

![キュー セマンティクスの図](./images/queue-semantics.png)

<span data-ttu-id="70960-162">一方、Event Hubs は、ストリーミング セマンティクスを使います。</span><span class="sxs-lookup"><span data-stu-id="70960-162">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="70960-163">コンシューマーは、独自のペースでストリームを独立して読み取ります。</span><span class="sxs-lookup"><span data-stu-id="70960-163">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="70960-164">各コンシューマーには、ストリームの現在位置を追跡する責任があります。</span><span class="sxs-lookup"><span data-stu-id="70960-164">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="70960-165">コンシューマーは、事前定義された間隔で永続的ストレージに現在位置を書き込む必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-165">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="70960-166">このように、コンシューマーで障害が発生した場合 (たとえば、コンシューマーがクラッシュした場合や、ホストに障害が発生した場合)、新しいインスタンスは最後に記録された位置からストリームの読み取りを再開できます。</span><span class="sxs-lookup"><span data-stu-id="70960-166">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="70960-167">このプロセスを "*チェックポイント処理*" と呼びます。</span><span class="sxs-lookup"><span data-stu-id="70960-167">This process is called *checkpointing*.</span></span>

<span data-ttu-id="70960-168">パフォーマンス上の理由から、コンシューマーは一般に各メッセージの後にはチェックポイント処理を行いません。</span><span class="sxs-lookup"><span data-stu-id="70960-168">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="70960-169">代わりに、*n* メッセージを処理した後や *n* 秒ごとなど、固定間隔でチェックポイント処理を行います。</span><span class="sxs-lookup"><span data-stu-id="70960-169">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="70960-170">結果として、新しいインスタンスは常に最新のチェックポイントから取得するため、コンシューマーが失敗した場合は一部のイベントが 2 回処理されます。</span><span class="sxs-lookup"><span data-stu-id="70960-170">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="70960-171">この場合、頻繁なチェックポイント処理でパフォーマンスが低下する可能性がありますが、チェックポイント処理の頻度が低いとエラー発生後に再実行するイベントが多くなるというトレードオフがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-171">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>

![ストリーム セマンティクスの図](./images/stream-semantics.png)

<span data-ttu-id="70960-173">Event Hubs は、競合コンシューマー用に設計されていません。</span><span class="sxs-lookup"><span data-stu-id="70960-173">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="70960-174">複数のコンシューマーがストリームを読み取ることができますが、それぞれが独立してストリームを走査します。</span><span class="sxs-lookup"><span data-stu-id="70960-174">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="70960-175">代わりに、Event Hubs は、パーティション分割されたコンシューマー パターンを使います。</span><span class="sxs-lookup"><span data-stu-id="70960-175">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="70960-176">Event hub には、最大 32 個のパーティションがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-176">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="70960-177">水平スケールは、各パーティションに個別のコンシューマーを割り当てることによって実現されます。</span><span class="sxs-lookup"><span data-stu-id="70960-177">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="70960-178">これはドローン配信ワークフローでどのような意味を持つでしょうか。</span><span class="sxs-lookup"><span data-stu-id="70960-178">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="70960-179">Event Hubs のメリットを最大限に活用するために、Delivery Scheduler は、次に進む前に各メッセージが処理されるのを待つことができません。</span><span class="sxs-lookup"><span data-stu-id="70960-179">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="70960-180">待った場合は、ほとんどの時間をネットワーク呼び出しの完了の待機に費やすことになります。</span><span class="sxs-lookup"><span data-stu-id="70960-180">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="70960-181">代わりに、バックエンド サービスへの非同期呼び出しを使って、メッセージのバッチを並列に処理する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-181">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="70960-182">このように、正しいチェックポイント処理戦略の選択も重要です。</span><span class="sxs-lookup"><span data-stu-id="70960-182">As we'll see, choosing the right checkpointing strategy is also important.</span></span>

## <a name="workflow"></a><span data-ttu-id="70960-183">ワークフロー</span><span class="sxs-lookup"><span data-stu-id="70960-183">Workflow</span></span>

<span data-ttu-id="70960-184">メッセージの読み取りと処理について、イベント プロセッサ ホスト、Service Bus キュー、および IotHub React ライブラリという 3 つのオプションを検討しました。</span><span class="sxs-lookup"><span data-stu-id="70960-184">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="70960-185">IoTHub React を選びましたが、その理由を理解するには、イベント プロセッサ ホストから開始するのが役立ちます。</span><span class="sxs-lookup"><span data-stu-id="70960-185">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span>

### <a name="event-processor-host"></a><span data-ttu-id="70960-186">イベント プロセッサ ホスト</span><span class="sxs-lookup"><span data-stu-id="70960-186">Event Processor Host</span></span>

<span data-ttu-id="70960-187">イベント プロセッサ ホストは、メッセージ バッチ処理用に設計されています。</span><span class="sxs-lookup"><span data-stu-id="70960-187">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="70960-188">アプリケーションは `IEventProcessor` インターフェイスを実装し、プロセッサ ホストはイベント ハブのパーティションごとに 1 つのイベント プロセッサ インスタンスを作成します。</span><span class="sxs-lookup"><span data-stu-id="70960-188">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="70960-189">イベント プロセッサ ホストは、イベント メッセージのバッチで各イベント プロセッサの `ProcessEventsAsync` メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="70960-189">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="70960-190">アプリケーションは `ProcessEventsAsync` メソッドの内部のチェックポイント処理のタイミングを制御し、イベント プロセッサ ホストはチェックポイントを Azure ストレージに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="70960-190">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span>

<span data-ttu-id="70960-191">パーティション内で、イベント プロセッサ ホストは `ProcessEventsAsync` が戻るのを待ってから、次のバッチでもう一度呼び出します。</span><span class="sxs-lookup"><span data-stu-id="70960-191">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="70960-192">この手法では、イベント処理コードが再入可能である必要がないため、プログラミング モデルが簡略化されます。</span><span class="sxs-lookup"><span data-stu-id="70960-192">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="70960-193">ただし、これはイベント プロセッサが一度に 1 つのバッチを処理することも意味するため、プロセッサ ホストがメッセージを取り込む速度が制限されます。</span><span class="sxs-lookup"><span data-stu-id="70960-193">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE]
> <span data-ttu-id="70960-194">プロセッサ ホストは、スレッドをブロックするという意味では実際には "*待機*" しません。</span><span class="sxs-lookup"><span data-stu-id="70960-194">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="70960-195">`ProcessEventsAsync` メソッドは非同期であるため、プロセッサ ホストはメソッドの実行中に他の作業を行うことができます。</span><span class="sxs-lookup"><span data-stu-id="70960-195">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="70960-196">ただし、メソッドが戻るまで、そのパーティションのメッセージの別のバッチは配信されません。</span><span class="sxs-lookup"><span data-stu-id="70960-196">But it won't deliver another batch of messages for that partition until the method returns.</span></span>

<span data-ttu-id="70960-197">ドローン アプリケーションでは、メッセージのバッチを並列に処理することができます。</span><span class="sxs-lookup"><span data-stu-id="70960-197">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="70960-198">ただし、バッチ全体の完了の待機によってボトルネックが生じることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-198">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="70960-199">処理の速度は、バッチ内で最も遅いメッセージの速度以下になります。</span><span class="sxs-lookup"><span data-stu-id="70960-199">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="70960-200">応答時間の変動により、少数の低速な応答がシステム全体の速度を低下させる "ロング テール" が作成されることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-200">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="70960-201">パフォーマンス テストでは、この手法を使うとターゲット スループットが達成されませんでした。</span><span class="sxs-lookup"><span data-stu-id="70960-201">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="70960-202">これは、イベント プロセッサ ホストの使用を避ける必要があるという意味では "*ありません*"。</span><span class="sxs-lookup"><span data-stu-id="70960-202">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="70960-203">ただし、高いスループットを実現するには、`ProcesssEventsAsync` メソッド内での実行時間の長いタスクの実行は避けてください。</span><span class="sxs-lookup"><span data-stu-id="70960-203">But for high throughput, avoid doing any long-running tasks inside the `ProcesssEventsAsync` method.</span></span> <span data-ttu-id="70960-204">各バッチを迅速に処理します。</span><span class="sxs-lookup"><span data-stu-id="70960-204">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="70960-205">IotHub React</span><span class="sxs-lookup"><span data-stu-id="70960-205">IotHub React</span></span>

<span data-ttu-id="70960-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) は、Event Hub からイベントを読み取るための Akka Streams ライブラリです。</span><span class="sxs-lookup"><span data-stu-id="70960-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="70960-207">Akka Streams は、[Reactive Streams](https://www.reactive-streams.org/) 仕様を実装するストリーム ベースのプログラミング フレームワークです。</span><span class="sxs-lookup"><span data-stu-id="70960-207">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="70960-208">すべてのストリーミング操作が非同期的に実行され、パイプラインが背圧を適切に処理する効率的なストリーミング パイプラインを構築する方法を提供します。</span><span class="sxs-lookup"><span data-stu-id="70960-208">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="70960-209">背圧は、ダウンストリームのコンシューマーが受信できる速度よりも高速にイベント ソースがイベントを生成する場合に発生します。これはまさに、ドローン配信システムにトラフィックの急増がある状況です。</span><span class="sxs-lookup"><span data-stu-id="70960-209">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="70960-210">バックエンド サービスの速度が低下すると、IoTHub React の速度が低下します。</span><span class="sxs-lookup"><span data-stu-id="70960-210">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="70960-211">容量を増やすと、IoTHub React はパイプラインを通じてより多くのメッセージをプッシュします。</span><span class="sxs-lookup"><span data-stu-id="70960-211">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="70960-212">Akka Streams も、Event Hubs からのイベントのストリーミング用のとても自然なプログラミング モデルです。</span><span class="sxs-lookup"><span data-stu-id="70960-212">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="70960-213">イベントのバッチをループする代わりに、各イベントに適用される操作のセットを定義し、Akka Streams でストリーミングを処理します。</span><span class="sxs-lookup"><span data-stu-id="70960-213">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="70960-214">Akka Streams は、"*ソース*"、"*フロー*"、"*シンク*" の観点でストリーミング パイプラインを定義します。</span><span class="sxs-lookup"><span data-stu-id="70960-214">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="70960-215">ソースは出力ストリームを生成し、フローは入力ストリームを処理して出力ストリームを生成します。シンクは出力を生成せずにストリームを消費します。</span><span class="sxs-lookup"><span data-stu-id="70960-215">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="70960-216">Akka Streams パイプラインを設定する Scheduler サービスのコードを次に示します。</span><span class="sxs-lookup"><span data-stu-id="70960-216">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="70960-217">このコードは、Event Hubs をソースとして構成します。</span><span class="sxs-lookup"><span data-stu-id="70960-217">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="70960-218">`map` ステートメントは、各イベント メッセージを、配信要求を表す Java クラスに逆シリアル化します。</span><span class="sxs-lookup"><span data-stu-id="70960-218">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="70960-219">`filter` ステートメントは、ストリームから `null` オブジェクトを削除します。これにより、メッセージを逆シリアル化できないケースを防止します。</span><span class="sxs-lookup"><span data-stu-id="70960-219">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="70960-220">`via` ステートメントは、各配信要求を処理するフローにソースを結合します。</span><span class="sxs-lookup"><span data-stu-id="70960-220">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="70960-221">`to` メソッドは、IoTHub React に組み込まれているチェックポイント シンクにフローを結合します。</span><span class="sxs-lookup"><span data-stu-id="70960-221">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="70960-222">IoTHub React は、Event Host Processor とは異なるチェックポイント処理戦略を使います。</span><span class="sxs-lookup"><span data-stu-id="70960-222">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="70960-223">チェックポイントはチェックポイント シンクによって書き込まれます。これはパイプラインの終了段階です。</span><span class="sxs-lookup"><span data-stu-id="70960-223">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="70960-224">Akka Streams の設計では、パイプラインはシンクがチェックポイントを書き込んでいるときにデータのストリーミングを続行できます。</span><span class="sxs-lookup"><span data-stu-id="70960-224">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="70960-225">つまり、アップストリームの処理段階は、チェックポイント処理が行われるのを待つ必要がありません。</span><span class="sxs-lookup"><span data-stu-id="70960-225">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="70960-226">タイムアウトの後、または一定数のメッセージが処理された後にチェックポイント処理が行われるように構成することができます。</span><span class="sxs-lookup"><span data-stu-id="70960-226">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="70960-227">`deliveryProcessor` メソッドは、Akka Streams フローを作成します。</span><span class="sxs-lookup"><span data-stu-id="70960-227">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(),
                        delivery.getMessageFromDevice().properties());

        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }

        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="70960-228">フローは、各メッセージの処理の実際の作業を行う静的な `processDeliveryRequestAsync` メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="70960-228">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="70960-229">IoTHub React でのスケーリング</span><span class="sxs-lookup"><span data-stu-id="70960-229">Scaling with IoTHub React</span></span>

<span data-ttu-id="70960-230">Scheduler サービスは、各コンテナー インスタンスが 1 つのパーティションから読み取るように設計されています。</span><span class="sxs-lookup"><span data-stu-id="70960-230">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="70960-231">たとえば、Event Hub に 32 のパーティションがある場合、Scheduler サービスは 32 のレプリカと共にデプロイされます。</span><span class="sxs-lookup"><span data-stu-id="70960-231">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="70960-232">このため、水平スケーリングの観点から高い柔軟性に対応できます。</span><span class="sxs-lookup"><span data-stu-id="70960-232">This allows for a lot of flexibility in terms of horizontal scaling.</span></span>

<span data-ttu-id="70960-233">クラスターのサイズによっては、クラスター内のノードで複数の Scheduler サービス ポッドが実行されることがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-233">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="70960-234">ただし、Scheduler サービスにより多くのリソースが必要な場合は、より多くのノードにポッドを分散するためにクラスターをスケールアウトできます。</span><span class="sxs-lookup"><span data-stu-id="70960-234">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="70960-235">Scheduler サービスはメモリとスレッドに依存するため、パフォーマンスは VM のサイズとノードあたりのポッド数に大きく依存することがパフォーマンス テストで示されました。</span><span class="sxs-lookup"><span data-stu-id="70960-235">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="70960-236">各インスタンスは、どの Event Hubs パーティションから読み取るかを知る必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-236">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="70960-237">パーティション番号を構成するために、Kubernetes の [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) リソースの種類を利用しました。</span><span class="sxs-lookup"><span data-stu-id="70960-237">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="70960-238">StatefulSet のポッドには、数値インデックスを含む永続的な識別子があります。</span><span class="sxs-lookup"><span data-stu-id="70960-238">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="70960-239">具体的には、ポッド名は `<statefulset name>-<index>` で、この値は Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/) を通じてコンテナーで使用できます。</span><span class="sxs-lookup"><span data-stu-id="70960-239">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="70960-240">実行時に、Scheduler サービスはポッド名を読み取り、ポッド インデックスをパーティション ID として使います。</span><span class="sxs-lookup"><span data-stu-id="70960-240">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="70960-241">Scheduler サービスをさらにスケールアウトする必要がある場合は、イベント ハブ パーティションごとに複数のポッドを割り当てて、複数のポッドが各パーティションを読み取るようにすることができます。</span><span class="sxs-lookup"><span data-stu-id="70960-241">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="70960-242">ただし、その場合は、各インスタンスが割り当てられたパーティション内のすべてのイベントを読み取ります。</span><span class="sxs-lookup"><span data-stu-id="70960-242">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="70960-243">処理の重複を避けるために、ハッシュ アルゴリズムを使って、各インスタンスがメッセージの一部をスキップするようにする必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-243">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="70960-244">こうすれば、複数のリーダーがストリームを使用できますが、各メッセージは 1 つのインスタンスによってのみ処理されます。</span><span class="sxs-lookup"><span data-stu-id="70960-244">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span>

![イベント ハブ ハッシュの図](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="70960-246">Service Bus キュー</span><span class="sxs-lookup"><span data-stu-id="70960-246">Service Bus queues</span></span>

<span data-ttu-id="70960-247">検討した 3 番目のオプションは、Event Hubs から Service Bus キューにメッセージをコピーし、Scheduler サービスで Service Bus からメッセージを読み取ることでした。</span><span class="sxs-lookup"><span data-stu-id="70960-247">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="70960-248">Service Bus にコピーするためにのみ受信要求を Event Hubs に書き込むのは奇妙に思えるかもしれません。</span><span class="sxs-lookup"><span data-stu-id="70960-248">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="70960-249">しかし、各サービスのさまざまな長所を活用することが目的でした。Service Bus のキュー セマンティクスを活用して競合コンシューマー パターンを持つワークロードを処理しながら、Event Hubs を使って大量のトラフィックの急増に対応します。</span><span class="sxs-lookup"><span data-stu-id="70960-249">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="70960-250">持続的なスループットのターゲットは、予想されるピーク時の負荷より小さいため、Service Bus キューの処理はメッセージ インジェストの処理ほど高速である必要はありません。</span><span class="sxs-lookup"><span data-stu-id="70960-250">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>

<span data-ttu-id="70960-251">この手法を使って、概念実証の実装で 1 秒あたり約 4 K 操作を実現しました。</span><span class="sxs-lookup"><span data-stu-id="70960-251">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="70960-252">これらのテストでは、実際の作業を実行しないモック バックエンド サービスを使いましたが、単純に固定量のサービスあたり待機時間が追加されました。</span><span class="sxs-lookup"><span data-stu-id="70960-252">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="70960-253">パフォーマンスの数値は、Service Bus の理論上の最大値よりもはるかに小さいことにご注意ください。</span><span class="sxs-lookup"><span data-stu-id="70960-253">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="70960-254">不一致について考えられる原因は次のとおりです。</span><span class="sxs-lookup"><span data-stu-id="70960-254">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="70960-255">接続プールの制限、並列処理の程度、プリフェッチ数、バッチ サイズなど、さまざまなクライアント パラメーターの値が最適でない。</span><span class="sxs-lookup"><span data-stu-id="70960-255">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="70960-256">ネットワーク I/O のボトルネック。</span><span class="sxs-lookup"><span data-stu-id="70960-256">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="70960-257">[ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read) ではなく [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) モードを使ったため、メッセージの少なくとも 1 回の配信を保証する必要があった。</span><span class="sxs-lookup"><span data-stu-id="70960-257">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="70960-258">さらにパフォーマンス テストを行うと根本原因が見つかり、これらの問題を解決できる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="70960-258">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="70960-259">しかし、IotHub React がパフォーマンス ターゲットを満たしていたため、このオプションを選びました。</span><span class="sxs-lookup"><span data-stu-id="70960-259">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="70960-260">とは言うものの、Service Bus はこのシナリオで有効なオプションです。</span><span class="sxs-lookup"><span data-stu-id="70960-260">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="70960-261">エラー処理</span><span class="sxs-lookup"><span data-stu-id="70960-261">Handling failures</span></span>

<span data-ttu-id="70960-262">考慮すべき 3 つの一般的なエラー クラスがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-262">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="70960-263">ダウンストリーム サービスに、単独では解消できない可能性が高い、一時的ではないエラーがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-263">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="70960-264">一時的でないエラーには、メソッドへの無効な入力などの通常のエラー条件が含まれます。</span><span class="sxs-lookup"><span data-stu-id="70960-264">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="70960-265">アプリケーション コードのハンドルされない例外やプロセスのクラッシュも含まれます。</span><span class="sxs-lookup"><span data-stu-id="70960-265">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="70960-266">この種類のエラーが発生した場合は、ビジネス トランザクション全体をエラーとしてマークする必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-266">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="70960-267">既に成功した同じトランザクションの他のステップを元に戻すことが必要な場合があります。</span><span class="sxs-lookup"><span data-stu-id="70960-267">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="70960-268">(下の「補正トランザクション」をご覧ください。)</span><span class="sxs-lookup"><span data-stu-id="70960-268">(See Compensating Transactions, below.)</span></span>

2. <span data-ttu-id="70960-269">ダウンストリーム サービスで、ネットワーク タイムアウトなどの一時的なエラーが発生している可能性があります。</span><span class="sxs-lookup"><span data-stu-id="70960-269">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="70960-270">多くの場合、これらのエラーは呼び出しを再試行するだけで解決できます。</span><span class="sxs-lookup"><span data-stu-id="70960-270">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="70960-271">一定回数やり直した後も操作がまだ失敗する場合は、一時的でないエラーと見なされます。</span><span class="sxs-lookup"><span data-stu-id="70960-271">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span>

3. <span data-ttu-id="70960-272">(たとえば、ノードのクラッシュが原因で) Scheduler サービス自体に障害が発生している可能性があります。</span><span class="sxs-lookup"><span data-stu-id="70960-272">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="70960-273">その場合、Kubernetes はサービスの新しいインスタンスを起動します。</span><span class="sxs-lookup"><span data-stu-id="70960-273">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="70960-274">ただし、既に進行中のトランザクションを再開する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-274">However, any transactions that were already in progress must be resumed.</span></span>

## <a name="compensating-transactions"></a><span data-ttu-id="70960-275">補正トランザクション</span><span class="sxs-lookup"><span data-stu-id="70960-275">Compensating transactions</span></span>

<span data-ttu-id="70960-276">一時的でないエラーが発生した場合、現在のトランザクションは、1 つ以上のステップが既に正常に完了している "*部分的に失敗*" の状態になっている可能性があります。</span><span class="sxs-lookup"><span data-stu-id="70960-276">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="70960-277">たとえば、ドローン サービスがドローンを既にスケジュールしている場合は、ドローンをキャンセルする必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-277">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="70960-278">その場合、アプリケーションは[補正トランザクション](../patterns/compensating-transaction.md)を使って成功したステップを元に戻す必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-278">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="70960-279">場合によっては、これは外部システムで、または手動プロセスで行う必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-279">In some cases, this must be done by an external system or even by a manual process.</span></span>

<span data-ttu-id="70960-280">補正トランザクションのロジックが複雑な場合は、このプロセスを担当する別のサービスを作成することを検討します。</span><span class="sxs-lookup"><span data-stu-id="70960-280">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="70960-281">ドローン配信アプリケーションでは、Scheduler サービスは失敗した操作を専用のキューに格納します。</span><span class="sxs-lookup"><span data-stu-id="70960-281">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="70960-282">Supervisor と呼ばれる独立したマイクロサービスは、このキューから読み取り、補正が必要なサービスに対してキャンセル API を呼び出します。</span><span class="sxs-lookup"><span data-stu-id="70960-282">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="70960-283">これは [Scheduler Agent Supervisor パターン][scheduler-agent-supervisor]のバリエーションです。</span><span class="sxs-lookup"><span data-stu-id="70960-283">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="70960-284">Supervisor サービスは、テキストまたは電子メールによるユーザーへの通知や操作ダッシュボードへのアラートの送信などの他の操作も実行できます。</span><span class="sxs-lookup"><span data-stu-id="70960-284">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span>

![Supervisor マイクロサービスを示す図](./images/supervisor.png)

## <a name="idempotent-versus-non-idempotent-operations"></a><span data-ttu-id="70960-286">べき等操作と非べき等操作</span><span class="sxs-lookup"><span data-stu-id="70960-286">Idempotent versus non-idempotent operations</span></span>

<span data-ttu-id="70960-287">要求が失われないようにするために、Scheduler サービスはすべてのメッセージが少なくとも 1 回処理されることを保証する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-287">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="70960-288">Event Hubs は、クライアントがチェックポイント処理を正しく行った場合に少なくとも 1 回の配信を保証できます。</span><span class="sxs-lookup"><span data-stu-id="70960-288">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="70960-289">Scheduler サービスがクラッシュした場合は、1 つ以上のクライアント要求の処理の途中である可能性があります。</span><span class="sxs-lookup"><span data-stu-id="70960-289">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="70960-290">これらのメッセージは、Scheduler の別のインスタンスによって取得され、再処理されます。</span><span class="sxs-lookup"><span data-stu-id="70960-290">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="70960-291">要求が 2 回処理されるとどうなるでしょうか。</span><span class="sxs-lookup"><span data-stu-id="70960-291">What happens if a request is processed twice?</span></span> <span data-ttu-id="70960-292">作業の重複を避けることが重要です。</span><span class="sxs-lookup"><span data-stu-id="70960-292">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="70960-293">同じパッケージに 2 つのドローンを送信することは望ましくありません。</span><span class="sxs-lookup"><span data-stu-id="70960-293">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="70960-294">1 つの手法は、すべての操作をべき等となるように設計することです。</span><span class="sxs-lookup"><span data-stu-id="70960-294">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="70960-295">操作は、最初の呼び出しの後に複数回呼び出しても副次的な影響が生じない場合はべき等です。</span><span class="sxs-lookup"><span data-stu-id="70960-295">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="70960-296">つまり、クライアントは操作を 1 回、2 回、または複数回呼び出すことができ、その結果は同じになります。</span><span class="sxs-lookup"><span data-stu-id="70960-296">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="70960-297">基本的に、サービスは重複する呼び出しを無視する必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-297">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="70960-298">副次的な影響のあるメソッドをべき等とするには、サービスが重複する呼び出しを検出できる必要があります。</span><span class="sxs-lookup"><span data-stu-id="70960-298">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="70960-299">たとえば、サービスで新しい ID を生成するのではなく、呼び出し元が ID を割り当てるようにすることができます。</span><span class="sxs-lookup"><span data-stu-id="70960-299">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="70960-300">サービスは、重複する ID を確認できます。</span><span class="sxs-lookup"><span data-stu-id="70960-300">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="70960-301">HTTP 仕様では、GET、PUT、DELETE メソッドはべき等である必要があると規定されています。</span><span class="sxs-lookup"><span data-stu-id="70960-301">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="70960-302">POST メソッドは、べき等であることが保証されません。</span><span class="sxs-lookup"><span data-stu-id="70960-302">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="70960-303">POST メソッドで新しいリソースが作成される場合、通常、この操作がべき等であることは保証されません。</span><span class="sxs-lookup"><span data-stu-id="70960-303">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span>

<span data-ttu-id="70960-304">べき等メソッドを記述するのは常に簡単であるとは限りません。</span><span class="sxs-lookup"><span data-stu-id="70960-304">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="70960-305">別のオプションは、永続ストア内のすべてのトランザクションの進行状況を Scheduler で追跡することです。</span><span class="sxs-lookup"><span data-stu-id="70960-305">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="70960-306">メッセージを処理するたびに、永続ストアで状態が検索されます。</span><span class="sxs-lookup"><span data-stu-id="70960-306">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="70960-307">各ステップの後に、結果がストアに書き込まれます。</span><span class="sxs-lookup"><span data-stu-id="70960-307">After each step, it would write the result to the store.</span></span> <span data-ttu-id="70960-308">こ手法はパフォーマンスに影響することがあります。</span><span class="sxs-lookup"><span data-stu-id="70960-308">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="70960-309">例:べき等操作</span><span class="sxs-lookup"><span data-stu-id="70960-309">Example: Idempotent operations</span></span>

<span data-ttu-id="70960-310">HTTP 仕様では、PUT メソッドはべき等である必要があると規定されています。</span><span class="sxs-lookup"><span data-stu-id="70960-310">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="70960-311">仕様では、べき等を次のように定義しています。</span><span class="sxs-lookup"><span data-stu-id="70960-311">The specification defines idempotent this way:</span></span>

> <span data-ttu-id="70960-312">要求メソッドでの複数の同じ要求によるサーバーへの意図された影響が、単一のそのような要求の影響と同じである場合、そのメソッドは "べき等" と見なされます。</span><span class="sxs-lookup"><span data-stu-id="70960-312">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request.</span></span> <span data-ttu-id="70960-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="70960-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="70960-314">新しいエンティティを作成するときに、PUT と POST のセマンティクスの違いを理解しておくことが重要です。</span><span class="sxs-lookup"><span data-stu-id="70960-314">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="70960-315">どちらの場合も、クライアントは要求本文でエンティティの表現を送信します。</span><span class="sxs-lookup"><span data-stu-id="70960-315">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="70960-316">ただし、URI の意味は異なります。</span><span class="sxs-lookup"><span data-stu-id="70960-316">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="70960-317">POST メソッドでは、URI は、コレクションなど、新しいエンティティの親リソースを表します。</span><span class="sxs-lookup"><span data-stu-id="70960-317">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="70960-318">たとえば、新しい配信を作成するには、URI を `/api/deliveries` とすることができます。</span><span class="sxs-lookup"><span data-stu-id="70960-318">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="70960-319">サーバーは、エンティティを作成し、`/api/deliveries/39660` などの新しい URI を割り当てます。</span><span class="sxs-lookup"><span data-stu-id="70960-319">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="70960-320">この URI は、応答の Location ヘッダーで返されます。</span><span class="sxs-lookup"><span data-stu-id="70960-320">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="70960-321">クライアントが要求を送信するたびに、サーバーは新しい URI を持つ新しいエンティティを作成します。</span><span class="sxs-lookup"><span data-stu-id="70960-321">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="70960-322">PUT メソッドでは、URI はエンティティを識別します。</span><span class="sxs-lookup"><span data-stu-id="70960-322">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="70960-323">その URI を持つエンティティが既に存在する場合、サーバーは要求のバージョンで既存のエンティティを置換します。</span><span class="sxs-lookup"><span data-stu-id="70960-323">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="70960-324">その URI を持つエンティティが存在しない場合、サーバーはそのエンティティを作成します。</span><span class="sxs-lookup"><span data-stu-id="70960-324">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="70960-325">たとえば、クライアントが PUT 要求を `api/deliveries/39660` に送信するとします。</span><span class="sxs-lookup"><span data-stu-id="70960-325">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="70960-326">その URI での配信がないと仮定した場合、サーバーは新しい配信を作成します。</span><span class="sxs-lookup"><span data-stu-id="70960-326">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="70960-327">クライアントが同じ要求をもう一度送信した場合、サーバーは既存のエンティティを置換します。</span><span class="sxs-lookup"><span data-stu-id="70960-327">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="70960-328">PUT メソッドの配信サービスの実装を次に示します。</span><span class="sxs-lookup"><span data-stu-id="70960-328">Here is the Delivery service's implementation of the PUT method.</span></span>

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="70960-329">ほとんどの要求で新しいエンティティが作成されると予想されるため、メソッドはリポジトリ オブジェクトで `CreateAsync` をオプティミスティックに呼び出してから、リソースを更新することによって重複リソース例外を処理します。</span><span class="sxs-lookup"><span data-stu-id="70960-329">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span>

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md