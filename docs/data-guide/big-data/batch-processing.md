---
title: バッチ処理
description: ''
author: zoinerTejada
ms.date: 02/12/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: cloud-fundamentals
ms.openlocfilehash: ea8eb7ca5e4c06c03729f54428931d28a4f3fa5b
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/20/2019
ms.locfileid: "58243643"
---
# <a name="batch-processing"></a><span data-ttu-id="2823a-102">バッチ処理</span><span class="sxs-lookup"><span data-stu-id="2823a-102">Batch processing</span></span>

<span data-ttu-id="2823a-103">ビッグ データの一般的なシナリオは、保存されたデータのバッチ処理です。</span><span class="sxs-lookup"><span data-stu-id="2823a-103">A common big data scenario is batch processing of data at rest.</span></span> <span data-ttu-id="2823a-104">このシナリオでは、ソース アプリケーション自体またはオーケストレーション ワークフローによって、ソース データがデータ ストレージに読み込まれます。</span><span class="sxs-lookup"><span data-stu-id="2823a-104">In this scenario, the source data is loaded into data storage, either by the source application itself or by an orchestration workflow.</span></span> <span data-ttu-id="2823a-105">その後、データは、並列化されたジョブによってインプレースで処理されます。これは、オーケストレーション ワークフローによって開始することもできます。</span><span class="sxs-lookup"><span data-stu-id="2823a-105">The data is then processed in-place by a parallelized job, which can also be initiated by the orchestration workflow.</span></span> <span data-ttu-id="2823a-106">処理には複数の反復手順が含まれることがあり、処理後の変換された結果が分析データ ストアに読み込まれ、分析およびレポート コンポーネントによるクエリを実行できます。</span><span class="sxs-lookup"><span data-stu-id="2823a-106">The processing may include multiple iterative steps before the transformed results are loaded into an analytical data store, which can be queried by analytics and reporting components.</span></span>

<span data-ttu-id="2823a-107">たとえば、Web サーバーからのログがフォルダーにコピーされた後、夜間処理されて、Web アクティビティの日次レポートが生成されます。</span><span class="sxs-lookup"><span data-stu-id="2823a-107">For example, the logs from a web server might be copied to a folder and then processed overnight to generate daily reports of web activity.</span></span>

![バッチ処理パイプラインの図](./images/batch-pipeline.png)

## <a name="when-to-use-this-solution"></a><span data-ttu-id="2823a-109">このソリューションを使用する状況</span><span class="sxs-lookup"><span data-stu-id="2823a-109">When to use this solution</span></span>

<span data-ttu-id="2823a-110">バッチ処理は、単純なデータ変換からより完全な ETL (抽出-変換-読み込み) パイプラインに至るまで、さまざまなシナリオで使用されます。</span><span class="sxs-lookup"><span data-stu-id="2823a-110">Batch processing is used in a variety of scenarios, from simple data transformations to a more complete ETL (extract-transform-load) pipeline.</span></span> <span data-ttu-id="2823a-111">ビッグ データのコンテキストでは、バッチ処理は非常に大きなデータ セットを操作する可能性があり、計算にかなりの時間がかかります </span><span class="sxs-lookup"><span data-stu-id="2823a-111">In a big data context, batch processing may operate over very large data sets, where the computation takes significant time.</span></span> <span data-ttu-id="2823a-112">(例については、「[Lambda architecture](../big-data/index.md#lambda-architecture)」(ラムダ アーキテクチャ) を参照してください)。バッチ処理は、通常は、さらに対話型で調査することに至り、機械学習用のモデル化の準備が完了したデータを提供したり、分析とビジュアル化用に最適化されたデータ ストアにデータを書き込んだりします。</span><span class="sxs-lookup"><span data-stu-id="2823a-112">(For example, see [Lambda architecture](../big-data/index.md#lambda-architecture).) Batch processing typically leads to further interactive exploration, provides the modeling-ready data for machine learning, or writes the data to a data store that is optimized for analytics and visualization.</span></span>

<span data-ttu-id="2823a-113">バッチ処理の 1 つの例は、フラットな半構造化 CSV ファイルまたは JSON ファイルの大規模なセットを、さらにクエリを実行できる準備が整ったスキーマ化され、構造化された形式に変換することです。</span><span class="sxs-lookup"><span data-stu-id="2823a-113">One example of batch processing is transforming a large set of flat, semi-structured CSV or JSON files into a schematized and structured format that is ready for further querying.</span></span> <span data-ttu-id="2823a-114">通常、データは、取り込みに使用される生の形式 (CSV など) から、クエリを効率的に実行できるバイナリ形式に変換されます。これが行われるのは、データが列形式で格納され、多くの場合、データに関するインデックスとインライン統計が用意されるためです。</span><span class="sxs-lookup"><span data-stu-id="2823a-114">Typically the data is converted from the raw formats used for ingestion (such as CSV) into binary formats that are more performant for querying because they store data in a columnar format, and often provide indexes and inline statistics about the data.</span></span>

## <a name="challenges"></a><span data-ttu-id="2823a-115">課題</span><span class="sxs-lookup"><span data-stu-id="2823a-115">Challenges</span></span>

- <span data-ttu-id="2823a-116">**データの形式とエンコード**。</span><span class="sxs-lookup"><span data-stu-id="2823a-116">**Data format and encoding**.</span></span> <span data-ttu-id="2823a-117">デバッグ時の最も困難な問題の一部は、予期しない形式またはエンコードがファイルで使用されている場合に発生します。</span><span class="sxs-lookup"><span data-stu-id="2823a-117">Some of the most difficult issues to debug happen when files use an unexpected format or encoding.</span></span> <span data-ttu-id="2823a-118">たとえば、ソース ファイルで UTF-16 と UTF-8 エンコードの両方が使用されていたり、予期しない区切り文字 (スペースやタブ) や予期しない文字が含まれていたりすることがあります。</span><span class="sxs-lookup"><span data-stu-id="2823a-118">For example, source files might use a mix of UTF-16 and UTF-8 encoding, or contain unexpected delimiters (space versus tab), or include unexpected characters.</span></span> <span data-ttu-id="2823a-119">別の一般的な例は、区切り記号として解釈されるタブ、スペース、またはコンマが含まれているテキスト フィールドです。</span><span class="sxs-lookup"><span data-stu-id="2823a-119">Another common example is text fields that contain tabs, spaces, or commas that are interpreted as delimiters.</span></span> <span data-ttu-id="2823a-120">データの読み込みと解析ロジックは、これらの問題を検出して処理するのに十分な柔軟性を持っている必要があります。</span><span class="sxs-lookup"><span data-stu-id="2823a-120">Data loading and parsing logic must be flexible enough to detect and handle these issues.</span></span>

- <span data-ttu-id="2823a-121">**タイム スライスの調整**。</span><span class="sxs-lookup"><span data-stu-id="2823a-121">**Orchestrating time slices**.</span></span> <span data-ttu-id="2823a-122">多くの場合、ソース データは、年、月、日、時間別に整理された処理時間を反映するフォルダー階層に配置されます。</span><span class="sxs-lookup"><span data-stu-id="2823a-122">Often source data is placed in a folder hierarchy that reflects processing windows, organized by year, month, day, hour, and so on.</span></span> <span data-ttu-id="2823a-123">場合によっては、データが遅れて到着することがあります。</span><span class="sxs-lookup"><span data-stu-id="2823a-123">In some cases, data may arrive late.</span></span> <span data-ttu-id="2823a-124">たとえば、Web サーバーが失敗し、3 月 7 日のログが 3 月 9 日までフォルダーに保存されないとします。</span><span class="sxs-lookup"><span data-stu-id="2823a-124">For example, suppose that a web server fails, and the logs for March 7th don't end up in the folder for processing until March 9th.</span></span> <span data-ttu-id="2823a-125">遅すぎたためにそれらは単純に無視されるのでしょうか。</span><span class="sxs-lookup"><span data-stu-id="2823a-125">Are they just ignored because they're too late?</span></span> <span data-ttu-id="2823a-126">下流の処理ロジックは順序がばらばらのレコードを処理できるでしょうか。</span><span class="sxs-lookup"><span data-stu-id="2823a-126">Can the downstream processing logic handle out-of-order records?</span></span>

## <a name="architecture"></a><span data-ttu-id="2823a-127">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="2823a-127">Architecture</span></span>

<span data-ttu-id="2823a-128">バッチ処理アーキテクチャには、上の図に示した次の論理コンポーネントがあります。</span><span class="sxs-lookup"><span data-stu-id="2823a-128">A batch processing architecture has the following logical components, shown in the diagram above.</span></span>

- <span data-ttu-id="2823a-129">**データ ストレージ**。</span><span class="sxs-lookup"><span data-stu-id="2823a-129">**Data storage**.</span></span> <span data-ttu-id="2823a-130">通常は、さまざまな形式の大量の大容量ファイルのリポジトリとして機能できる分散ファイル ストアです。</span><span class="sxs-lookup"><span data-stu-id="2823a-130">Typically a distributed file store that can serve as a repository for high volumes of large files in various formats.</span></span> <span data-ttu-id="2823a-131">一般的に、この種類のストアは、しばしばData Lake と呼ばれます。</span><span class="sxs-lookup"><span data-stu-id="2823a-131">Generically, this kind of store is often referred to as a data lake.</span></span>

- <span data-ttu-id="2823a-132">**バッチ処理**。</span><span class="sxs-lookup"><span data-stu-id="2823a-132">**Batch processing**.</span></span> <span data-ttu-id="2823a-133">ビッグ データの大容量という性質は、多くの場合、ソリューションで、実行時間の長いバッチ ジョブを使用してデータ ファイルを処理し、フィルター処理や集計などを行って分析用のデータを準備する必要があることを意味します。</span><span class="sxs-lookup"><span data-stu-id="2823a-133">The high-volume nature of big data often means that solutions must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="2823a-134">通常、これらのジョブには、ソース ファイルの読み取り、ソース ファイルの処理、新しいファイルへの出力の書き込みが含まれます。</span><span class="sxs-lookup"><span data-stu-id="2823a-134">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span>

- <span data-ttu-id="2823a-135">**分析データ ストア**。</span><span class="sxs-lookup"><span data-stu-id="2823a-135">**Analytical data store**.</span></span> <span data-ttu-id="2823a-136">多くのビッグ データ ソリューションは、分析用にデータを準備した後、処理されたデータを分析ツールを使用してクエリを実行できる構造化された形式で提供するように設計されています。</span><span class="sxs-lookup"><span data-stu-id="2823a-136">Many big data solutions are designed to prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span>

- <span data-ttu-id="2823a-137">**分析とレポート**。</span><span class="sxs-lookup"><span data-stu-id="2823a-137">**Analysis and reporting**.</span></span> <span data-ttu-id="2823a-138">ほとんどのビッグ データ ソリューションの目的は、分析とレポートによってデータに関する実用的な情報を提供することにあります。</span><span class="sxs-lookup"><span data-stu-id="2823a-138">The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span>

- <span data-ttu-id="2823a-139">**オーケストレーション**。</span><span class="sxs-lookup"><span data-stu-id="2823a-139">**Orchestration**.</span></span> <span data-ttu-id="2823a-140">バッチ処理では、通常は、データ ストレージ、バッチ処理、分析データ ストア、およびレポート層にデータを移行するかコピーするための何らかのオーケストレーションが必要です。</span><span class="sxs-lookup"><span data-stu-id="2823a-140">With batch processing, typically some orchestration is required to migrate or copy the data into your data storage, batch processing, analytical data store, and reporting layers.</span></span>

## <a name="technology-choices"></a><span data-ttu-id="2823a-141">テクノロジの選択</span><span class="sxs-lookup"><span data-stu-id="2823a-141">Technology choices</span></span>

<span data-ttu-id="2823a-142">次のテクノロジは、Azure でのバッチ処理に推奨される選択肢です。</span><span class="sxs-lookup"><span data-stu-id="2823a-142">The following technologies are recommended choices for batch processing solutions in Azure.</span></span>

### <a name="data-storage"></a><span data-ttu-id="2823a-143">データ ストレージ</span><span class="sxs-lookup"><span data-stu-id="2823a-143">Data storage</span></span>

- <span data-ttu-id="2823a-144">**Azure Storage Blob コンテナー**。</span><span class="sxs-lookup"><span data-stu-id="2823a-144">**Azure Storage Blob Containers**.</span></span> <span data-ttu-id="2823a-145">多くの既存の Azure のビジネス プロセスでは、既に Azure Blob Storage を活用しているため、ビッグ データ ストア向けの適切な選択肢になっています。</span><span class="sxs-lookup"><span data-stu-id="2823a-145">Many existing Azure business processes already use Azure blob storage, making this a good choice for a big data store.</span></span>
- <span data-ttu-id="2823a-146">**Azure Data Lake Store**。</span><span class="sxs-lookup"><span data-stu-id="2823a-146">**Azure Data Lake Store**.</span></span> <span data-ttu-id="2823a-147">Azure Data Lake Store は、任意のサイズのファイルを格納できる豊富なセキュリティ オプションを備えた実質的に無制限のストレージであり、異種形式のデータの一元的なストアを必要とする非常に大規模なビッグ データ ソリューションに適した選択肢です。</span><span class="sxs-lookup"><span data-stu-id="2823a-147">Azure Data Lake Store offers virtually unlimited storage for any size of file, and extensive security options, making it a good choice for extremely large-scale big data solutions that require a centralized store for data in heterogeneous formats.</span></span>

<span data-ttu-id="2823a-148">詳しくは、[データ ストレージ](../technology-choices/data-storage.md)に関するページをご覧ください。</span><span class="sxs-lookup"><span data-stu-id="2823a-148">For more information, see [Data storage](../technology-choices/data-storage.md).</span></span>

<!-- markdownlint-disable MD024 -->

### <a name="batch-processing"></a><span data-ttu-id="2823a-149">バッチ処理</span><span class="sxs-lookup"><span data-stu-id="2823a-149">Batch processing</span></span>

<!-- markdownlint-enable MD024 -->

- <span data-ttu-id="2823a-150">**U-SQL**。</span><span class="sxs-lookup"><span data-stu-id="2823a-150">**U-SQL**.</span></span> <span data-ttu-id="2823a-151">U-SQL は、Azure Data Lake Analytics によって使用されるクエリ処理言語です。</span><span class="sxs-lookup"><span data-stu-id="2823a-151">U-SQL is the query processing language used by Azure Data Lake Analytics.</span></span> <span data-ttu-id="2823a-152">それは、SQL の宣言型の性質を C# の手続き型の拡張性と組み合わせたものであり、並列性を利用してデータを大規模に効率的に処理できるようにします。</span><span class="sxs-lookup"><span data-stu-id="2823a-152">It combines the declarative nature of SQL with the procedural extensibility of C#, and takes advantage of parallelism to enable efficient processing of data at massive scale.</span></span>
- <span data-ttu-id="2823a-153">**Hive**。</span><span class="sxs-lookup"><span data-stu-id="2823a-153">**Hive**.</span></span> <span data-ttu-id="2823a-154">Hive は、HDInsight を含む大半の Hadoop ディストリビューションでサポートされている SQL に似た言語です。</span><span class="sxs-lookup"><span data-stu-id="2823a-154">Hive is a SQL-like language that is supported in most Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="2823a-155">Azure Blob Storage と Azure Data Lake Store を含む HDFS と互換性のあるストアのデータを処理するために使用できます。</span><span class="sxs-lookup"><span data-stu-id="2823a-155">It can be used to process data from any HDFS-compatible store, including Azure blob storage and Azure Data Lake Store.</span></span>
- <span data-ttu-id="2823a-156">**Pig**。</span><span class="sxs-lookup"><span data-stu-id="2823a-156">**Pig**.</span></span> <span data-ttu-id="2823a-157">Pig は、HDInsight を含む多数の Hadoop ディストリビューションで使用される、宣言型のビッグ データ処理言語です。</span><span class="sxs-lookup"><span data-stu-id="2823a-157">Pig is a declarative big data processing language used in many Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="2823a-158">非構造化または半構造化データを処理するために特に便利です。</span><span class="sxs-lookup"><span data-stu-id="2823a-158">It is particularly useful for processing data that is unstructured or semi-structured.</span></span>
- <span data-ttu-id="2823a-159">**Spark**。</span><span class="sxs-lookup"><span data-stu-id="2823a-159">**Spark**.</span></span> <span data-ttu-id="2823a-160">Spark エンジンは、Java、Scala、および Python を含むさまざまな言語で記述されたバッチ処理プログラムをサポートします。</span><span class="sxs-lookup"><span data-stu-id="2823a-160">The Spark engine supports batch processing programs written in a range of languages, including Java, Scala, and Python.</span></span> <span data-ttu-id="2823a-161">Spark は、分散アーキテクチャを使用して、複数の worker ノード間でデータを並列で処理します。</span><span class="sxs-lookup"><span data-stu-id="2823a-161">Spark uses a distributed architecture to process data in parallel across multiple worker nodes.</span></span>

<span data-ttu-id="2823a-162">詳しくは、[バッチ処理](../technology-choices/batch-processing.md)に関するページをご覧ください。</span><span class="sxs-lookup"><span data-stu-id="2823a-162">For more information, see [Batch processing](../technology-choices/batch-processing.md).</span></span>

### <a name="analytical-data-store"></a><span data-ttu-id="2823a-163">分析データ ストア</span><span class="sxs-lookup"><span data-stu-id="2823a-163">Analytical data store</span></span>

- <span data-ttu-id="2823a-164">**SQL Data Warehouse**。</span><span class="sxs-lookup"><span data-stu-id="2823a-164">**SQL Data Warehouse**.</span></span> <span data-ttu-id="2823a-165">Azure SQL Data Warehouse は、SQL Server データベース テクノロジに基づく管理対象サービスであり、大規模なデータ ウェアハウスのワークロードをサポートするように最適化されています。</span><span class="sxs-lookup"><span data-stu-id="2823a-165">Azure SQL Data Warehouse is a managed service based on SQL Server database technologies and optimized to support large-scale data warehousing workloads.</span></span>
- <span data-ttu-id="2823a-166">**Spark SQL**。</span><span class="sxs-lookup"><span data-stu-id="2823a-166">**Spark SQL**.</span></span> <span data-ttu-id="2823a-167">Spark SQL は Spark 上に構築された API で、SQL 構文を使用してクエリを実行できるデータフレームとテーブルの作成をサポートします。</span><span class="sxs-lookup"><span data-stu-id="2823a-167">Spark SQL is an API built on Spark that supports the creation of dataframes and tables that can be queried using SQL syntax.</span></span>
- <span data-ttu-id="2823a-168">**HBase**。</span><span class="sxs-lookup"><span data-stu-id="2823a-168">**HBase**.</span></span> <span data-ttu-id="2823a-169">HBase は、待ち時間の短い NoSQL ストアで、構造化および半構造化データに対してクエリを実行するための高パフォーマンスで柔軟なオプションを提供します。</span><span class="sxs-lookup"><span data-stu-id="2823a-169">HBase is a low-latency NoSQL store that offers a high-performance, flexible option for querying structured and semi-structured data.</span></span>
- <span data-ttu-id="2823a-170">**Hive**。</span><span class="sxs-lookup"><span data-stu-id="2823a-170">**Hive**.</span></span> <span data-ttu-id="2823a-171">バッチ処理に適していることに加え、Hive は、概念的には一般的なリレーショナル データベース管理システムに類似するデータベース アーキテクチャを提供します。</span><span class="sxs-lookup"><span data-stu-id="2823a-171">In addition to being useful for batch processing, Hive offers a database architecture that is conceptually similar to that of a typical relational database management system.</span></span> <span data-ttu-id="2823a-172">Tez エンジンや Stinger Initiative などのイノベーションによる Hive クエリのパフォーマンスの向上は、シナリオによっては Hive テーブルを分析クエリのソースとして効率的に使用できることを意味します。</span><span class="sxs-lookup"><span data-stu-id="2823a-172">Improvements in Hive query performance through innovations like the Tez engine and Stinger initiative mean that Hive tables can be used effectively as sources for analytical queries in some scenarios.</span></span>

<span data-ttu-id="2823a-173">詳しくは、[分析データ ストア](../technology-choices/analytical-data-stores.md)に関するページをご覧ください。</span><span class="sxs-lookup"><span data-stu-id="2823a-173">For more information, see [Analytical data stores](../technology-choices/analytical-data-stores.md).</span></span>

### <a name="analytics-and-reporting"></a><span data-ttu-id="2823a-174">分析とレポート</span><span class="sxs-lookup"><span data-stu-id="2823a-174">Analytics and reporting</span></span>

- <span data-ttu-id="2823a-175">**Azure Analysis Services**。</span><span class="sxs-lookup"><span data-stu-id="2823a-175">**Azure Analysis Services**.</span></span> <span data-ttu-id="2823a-176">多くのビッグ データ ソリューションでは、レポート、ダッシュボード、および対話型の "スライス アンド ダイス" 分析のベースにすることができる一元的なオンライン分析処理 (OLAP) データ モデル (しばしばキューブとも呼ばれます) を含めることによって、従来のエンタープライズ ビジネス インテリジェンス アーキテクチャをエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="2823a-176">Many big data solutions emulate traditional enterprise business intelligence architectures by including a centralized online analytical processing (OLAP) data model (often referred to as a cube) on which reports, dashboards, and interactive “slice and dice” analysis can be based.</span></span> <span data-ttu-id="2823a-177">Azure Analysis Services では、このニーズを満たすために、表形式モデルの作成をサポートしています。</span><span class="sxs-lookup"><span data-stu-id="2823a-177">Azure Analysis Services supports the creation of tabular models to meet this need.</span></span>
- <span data-ttu-id="2823a-178">**Power BI**。</span><span class="sxs-lookup"><span data-stu-id="2823a-178">**Power BI**.</span></span> <span data-ttu-id="2823a-179">データ アナリストは、Power BI を使用して、OLAP モデル内のデータ モデルに基づいて、または分析データストアから直接、対話型のデータのビジュアル化を作成できます。</span><span class="sxs-lookup"><span data-stu-id="2823a-179">Power BI enables data analysts to create interactive data visualizations based on data models in an OLAP model or directly from an analytical data store.</span></span>
- <span data-ttu-id="2823a-180">**Microsoft Excel**。</span><span class="sxs-lookup"><span data-stu-id="2823a-180">**Microsoft Excel**.</span></span> <span data-ttu-id="2823a-181">Microsoft Excel は、世界で最も広く使用されているソフトウェア アプリケーションの 1 つであり、豊富なデータ分析とビジュアル化の機能を備えています。</span><span class="sxs-lookup"><span data-stu-id="2823a-181">Microsoft Excel is one of the most widely used software applications in the world, and offers a wealth of data analysis and visualization capabilities.</span></span> <span data-ttu-id="2823a-182">データ アナリストは、Excel を使用して、分析データ ストアからドキュメントのデータ モデルを構築したり、OLAP データ モデルから対話型のピボット テーブルとグラフにデータを取得したりできます。</span><span class="sxs-lookup"><span data-stu-id="2823a-182">Data analysts can use Excel to build document data models from analytical data stores, or to retrieve data from OLAP data models into interactive PivotTables and charts.</span></span>

<span data-ttu-id="2823a-183">詳しくは、[分析とレポート](../technology-choices/analysis-visualizations-reporting.md)に関するページをご覧ください。</span><span class="sxs-lookup"><span data-stu-id="2823a-183">For more information, see [Analytics and reporting](../technology-choices/analysis-visualizations-reporting.md).</span></span>

### <a name="orchestration"></a><span data-ttu-id="2823a-184">オーケストレーション</span><span class="sxs-lookup"><span data-stu-id="2823a-184">Orchestration</span></span>

- <span data-ttu-id="2823a-185">**Azure Data Factory**。</span><span class="sxs-lookup"><span data-stu-id="2823a-185">**Azure Data Factory**.</span></span> <span data-ttu-id="2823a-186">Azure Data Factory パイプラインを使用して、繰り返されるテンポラル ウィンドウに合わせてスケジュールされた一連のアクティビティを定義できます。</span><span class="sxs-lookup"><span data-stu-id="2823a-186">Azure Data Factory pipelines can be used to define a sequence of activities, scheduled for recurring temporal windows.</span></span> <span data-ttu-id="2823a-187">これらのアクティビティは、オンデマンド HDInsight クラスターの Hive、Pig、MapReduce、または Spark ジョブ、Azure Date Lake Analytics の U-SQL ジョブ、Azure SQL Data Warehouse または Azure SQL Database のストアド プロシージャと同じようにコピー操作を開始できます。</span><span class="sxs-lookup"><span data-stu-id="2823a-187">These activities can initiate data copy operations as well as Hive, Pig, MapReduce, or Spark jobs in on-demand HDInsight clusters; U-SQL jobs in Azure Date Lake Analytics; and stored procedures in Azure SQL Data Warehouse or Azure SQL Database.</span></span>
- <span data-ttu-id="2823a-188">**Oozie** と **Sqoop**。</span><span class="sxs-lookup"><span data-stu-id="2823a-188">**Oozie** and **Sqoop**.</span></span> <span data-ttu-id="2823a-189">Oozie は、Apache Hadoop エコシステム向けのジョブ オートメーション エンジンであり、それを使用して、Hive、Pig、MapReduce ジョブと同じようにデータのコピー操作を開始してデータを処理でき、Sqoop ジョブと同じように HDFS データベースと SQL データベース間でデータをコピーできます。</span><span class="sxs-lookup"><span data-stu-id="2823a-189">Oozie is a job automation engine for the Apache Hadoop ecosystem and can be used to initiate data copy operations as well as Hive, Pig, and MapReduce jobs to process data and Sqoop jobs to copy data between HDFS and SQL databases.</span></span>

<span data-ttu-id="2823a-190">詳細については、[パイプラインのオーケストレーション](../technology-choices/pipeline-orchestration-data-movement.md)に関するページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="2823a-190">For more information, see [Pipeline orchestration](../technology-choices/pipeline-orchestration-data-movement.md)</span></span>
